{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef93f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Modules for Data Preprocessing\n",
    "\n",
    "# Used for loading in training data [Function #1 - load_raw_training_data()]\n",
    "import pandas as pd\n",
    "# Adjust column width settings to see all of the 'original_text' column\n",
    "pd.set_option('max_colwidth', 400)\n",
    "#Adjust notebook to display all rows if output is of a large dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Used for replacing '-LRB-' and '-RRB-' with left and right parentheses in original text repectively [Function #2 - replace_LRB_and_RRB()]\n",
    "import re\n",
    "\n",
    "# Used for label value changing in preprocessing training data [Function #6 - preprocessing_training_data()]\n",
    "import numpy as np\n",
    "\n",
    "# Used for tokenization when creating score values against extraneous resourses [Function #8 - extraneous_score_calculation()]\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# Used for Parts-of-Speech tagging [Function #14 - POS_preprocessing()]\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Used for Lemmatization [Function #15 - lemma_preprocessing()]\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Used for vectorization [Function # ]\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fc3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw WikiLarge Training Data from GitHub Repository\n",
    "def load_raw_training_data():\n",
    "    # WikiLarge Training Data is very large and was split into three CSV files load each of them in.\n",
    "    textData_1 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_1.csv')\n",
    "    textData_2 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_2.csv')\n",
    "    textData_3 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_3.csv')\n",
    "    \n",
    "    # Concatenate each of the parts together to get the original data in one dataframe\n",
    "    text_data = pd.concat([textData_1, textData_2, textData_3], ignore_index=True)\n",
    "    \n",
    "    # Return concatenated dataframe\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2998c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After searching for the first few 'original_text' entries presented in text_data.head() - it was determined\n",
    "# that '-LRB-' and '-RRB-' are left and right parentheses respectively. This function replaces those\n",
    "# text strings with their respective symbols.\n",
    "def replace_LRB_and_RRB(text):\n",
    "  # Replace the substring \"-LRB-\" with \"(\" in input string\n",
    "  new_string = re.sub(\"-LRB-\", \"(\", text)\n",
    "\n",
    "  # Replace the substring \"-RRB-\" with \")\" in new_string\n",
    "  second_string = re.sub(\"-RRB-\", \")\", new_string)\n",
    "\n",
    "  # Return the output of the second replacement\n",
    "  return second_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef1c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the finding of '-LRB-' and '-RRB-', this function replaces every character in a string that is not a parentheses with no text\n",
    "def find_parentheses(text):\n",
    "    punctuation_string = obtain_non_Alphanumeric(text)\n",
    "    new_string = re.sub(\"[^()]\", \"\", punctuation_string)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc95627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find any uneven parentheses within the 'original_text' column\n",
    "def determine_uneven_parentheses(text):\n",
    "  # Use previously generated function to find all parentheses within the 'original_text' column\n",
    "  parentheses_only = find_parentheses(text)\n",
    "\n",
    "  # Generate a list containing a single string of a closed parentheses\n",
    "  parentheses_string_list = ['()']\n",
    "\n",
    "  # While any closed parentheses exist in the parentheses column\n",
    "  while any(x in parentheses_only for x in parentheses_string_list):\n",
    "    # Replace the closed parentheses with no text\n",
    "    for paren in parentheses_string_list:\n",
    "        parentheses_only = parentheses_only.replace(paren, \"\")\n",
    "\n",
    "  # Output result as a boolean to determine if string parentheses_only has been reduce to an empty string\n",
    "  result = not parentheses_only\n",
    "\n",
    "  # Return boolean value as 0 or 1 - 0 indicating that the 'original_text' column has closed parentheses\n",
    "  if result == False:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36046154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain any non-alphanumeric characters\n",
    "def obtain_non_Alphanumeric(text):\n",
    "  # replace all non-alphanumeric characters of an input string with no text to a new output called 'new_string'\n",
    "  new_string, number_of_subs = re.subn(\"[a-zA-Z0-9]\", \"\", text)\n",
    "\n",
    "  # replace all white space characters of 'new_string' with no text to the output 'second_string'\n",
    "  second_string, second_subs = re.subn(\"\\s\", \"\", new_string)\n",
    "\n",
    "  # return 'second_string'\n",
    "  return second_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e81d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined previous functions into large preprocessing function\n",
    "\n",
    "# Additionally - find duplicate 'original_text' entries, find the mean of their label values - as some of them have\n",
    "# opposing label values - then remove all duplicates except for one with the mean label value adjusted to 0 or 1\n",
    "# based on rounding\n",
    "def preprocessing_training_data():\n",
    "    text_data = load_raw_training_data()\n",
    "    \n",
    "    # Convert binary 0 labels to -1 (this helps with keeping some of the duplicate entries by mean value calculation)\n",
    "    text_data['label'] = np.where(text_data['label'] < 1, -1, 1)\n",
    "    \n",
    "    # Separate out the duplicate entries from the individual entries - All duplicate entries are taken to \"duplicate_texts\" dataframe\n",
    "    duplicate_texts = text_data[text_data.original_text.duplicated(keep=False)].copy()\n",
    "    \n",
    "    # Individual entries can be used directly in the final version of the preprocessed dataframe\n",
    "    individual_texts = text_data[~text_data.original_text.duplicated(keep=False)].copy()\n",
    "    \n",
    "    # Group the duplicate text entries by the original text and find the mean value. \n",
    "    # If the mean value is negative, then most of the entries have been labeled as -1\n",
    "    # If the mean value is positive, then most of the entries have been labeled as 1\n",
    "    dup_group = duplicate_texts.groupby(['original_text'], as_index=False).mean()\n",
    "    \n",
    "    # Convert all positive values to 1 and all negative values to -1\n",
    "    dup_group['label'] = np.where(dup_group['label'] > 0, 1, dup_group['label'])\n",
    "    dup_group['label'] = np.where(dup_group['label'] < 0, -1, dup_group['label'])\n",
    "    \n",
    "    # If the label mean is 0, then it is an even split, and the text data cannot be used for classification\n",
    "    # Identify all rows with mean groupby label values of 0\n",
    "    zero_mean = dup_group[dup_group['label'] == 0]\n",
    "    \n",
    "    # Identify all rows with positive groupby label values\n",
    "    pos_mean = dup_group[dup_group['label'] > 0].copy()\n",
    "    \n",
    "    # Perform the same for all rows with negative groupby label values\n",
    "    neg_mean = dup_group[dup_group['label'] < 0].copy()\n",
    "    \n",
    "    # Recombine the acceptable duplicate entries with the original individual entries\n",
    "    new_text_data = pd.concat([pos_mean, neg_mean, individual_texts], ignore_index=True)\n",
    "    \n",
    "    # Convert the labels of -1 back to 0 as in the original training data\n",
    "    new_text_data['label'] = np.where(new_text_data['label'] < 0, 0, 1)\n",
    "    \n",
    "    # Replace \"-LRB-\" and \"-RRB-\" with left and right parentheses\n",
    "    new_text_data['original_text'] = new_text_data.original_text.apply(lambda x: replace_LRB_and_RRB(x))\n",
    "    \n",
    "    # Create a Column of only the punctuation using previously made function\n",
    "    new_text_data['punctuation'] = new_text_data.original_text.apply(lambda x: obtain_non_Alphanumeric(x))\n",
    "    \n",
    "    # Determine if a text entry has closed parentheses or not\n",
    "    new_text_data['closed_parentheses'] = new_text_data.original_text.apply(lambda x: determine_uneven_parentheses(x))\n",
    "    \n",
    "    return new_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130de8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which loads external resouce data provided with the WikiLarge data - those resources are:\n",
    "# 1) The Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "# 2) \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "# 3) Brysbaert et al Concreteness Ratings for 40 thousand English lemma words gathered via \n",
    "#    Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "def load_external_resource_data():\n",
    "    # Load Dale Chall word list as a list of strings\n",
    "    dale_chall = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/dale_chall.txt', header=None)\n",
    "    d_c_df = dale_chall.rename(columns={0:'words'})\n",
    "    d_c_list = d_c_df['words'].to_list()\n",
    "    \n",
    "    # Load AoA estimates for about 51 thousand English words, and return it as a dictionary\n",
    "    AoA = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/AoA_51715_words.csv', encoding='unicode_escape')\n",
    "    # Reduce the dataframe to the word and the AoA_Kup_lem score\n",
    "    AoA = AoA[['Word', 'AoA_Kup_lem']]\n",
    "    # Drop any rows where the AoA_Kup_lem score is not a value\n",
    "    AoA = AoA[AoA['AoA_Kup_lem'].notna()]\n",
    "    # Set the index of the dataframe to the words\n",
    "    AoA = AoA.set_index('Word')\n",
    "    # Take the AoA_Kup_lem score series out as a dictionary\n",
    "    AoA_dict = AoA['AoA_Kup_lem'].to_dict()\n",
    "    \n",
    "    # Load Brysbaert Concreteness ratings, and return it as a dictionary\n",
    "    Brysbaert = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt', delimiter='\\t')\n",
    "    # Reduce the dataframe to the word and Concreteness rating\n",
    "    Brysbaert = Brysbaert[['Word','Conc.M']]\n",
    "    # Remove any words that do not have a concreteness rating\n",
    "    Brysbaert = Brysbaert[Brysbaert['Conc.M'].notna()]\n",
    "    # Set the dataframe index to the word\n",
    "    Brysbaert = Brysbaert.set_index('Word')\n",
    "    # Take the Concreteness rating series out as a dictionary\n",
    "    Brysbaert_dict = Brysbaert['Conc.M'].to_dict()\n",
    "    \n",
    "    return d_c_list, AoA_dict, Brysbaert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2f71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate a score based on values from an external resource\n",
    "def extraneous_score_calculation(text, extraneous_dict):\n",
    "    # Replace all non-alphanumeric characters with a space, then make the letters lowercase, and \n",
    "    # subsequently tokenize the words\n",
    "    tokens = nltk.word_tokenize((re.sub(\"[^a-zA-Z0-9 ]\", \" \", text)).lower())\n",
    "    # Create an empty array to add score values into\n",
    "    score_array = []\n",
    "    \n",
    "    # For each token in the tokenize 'original_text'\n",
    "    for tok in tokens:\n",
    "        # Try to find the token in the extraneous dictionary and append its score to the array\n",
    "        try:\n",
    "            ind_score = extraneous_dict[tok]\n",
    "            score_array.append(ind_score)\n",
    "        # If unable to find the token, append a value of 0 to the array\n",
    "        except:\n",
    "            score_array.append(0)\n",
    "        # Return a normalized score for the 'original_text' column by summing the scores together and dividing by \n",
    "        # the total number of tokens.\n",
    "        return np.sum(score_array)/len(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3869b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use extraneous_score_calculation function to calculate AoA and Brysbaert Concreteness Scores\n",
    "def get_AoA_Brysbaert_features(new_text_data):\n",
    "    # Calculate AoA Score using extraneous_score_calculation function\n",
    "    new_text_data['AoA_score'] = new_text_data.original_text.apply(lambda x: extraneous_score_calculation(x, AoA_dict))\n",
    "    # Calculate Brysbaert Score using extraneous_score_calculation function\n",
    "    new_text_data['Brysbaert_score'] = new_text_data.original_text.apply(lambda x: extraneous_score_calculation(x, Brysbaert_dict))\n",
    "    \n",
    "    # Convert NaN in Both 'AoA_score' and 'Brysbaert_score' columns\n",
    "    new_text_data['AoA_score'] = new_text_data['AoA_score'].fillna(0)\n",
    "    new_text_data['Brysbaert_score'] = new_text_data['Brysbaert_score'].fillna(0)\n",
    "    \n",
    "    return new_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4adecf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire additional features such as:\n",
    "# 1) Normalized proportion of word tokens from Dale Chall list in 'original_text' column\n",
    "# 2) Number of tokens in 'original_text' column\n",
    "# 3) Average length of each word token in 'original_text' column\n",
    "# 4) Largest length of a word token in 'original_text' column\n",
    "# 5) Normalized proportion of non-alphanumeric characters in 'original_text' column\n",
    "# 6) Normalized proportion of decimal digit characters in 'original_text' column\n",
    "def get_more_features(list_of_docs, easy_word_list):\n",
    "    # List for number of word tokens in text passage\n",
    "    num_toks_l = []\n",
    "    # List for number of dale_chall terms in text passage, normalized to length of text passage\n",
    "    d_c_norm_l = []\n",
    "    # Value of average word length for a textual passage\n",
    "    avg_tok_len_l = []\n",
    "    # Value of max word length for a textual passage\n",
    "    max_tok_len_l = []\n",
    "    # Number of Non-alphanumeric characters\n",
    "    non_alpha_char_l =[]\n",
    "    # Number of Characters total\n",
    "    numbers_norm_l = [] #add ratio of number charicters to total\n",
    "    # Generate a set of words based on the second input of the function (a list of words)\n",
    "    s2=set(easy_word_list)\n",
    "    \n",
    "    \n",
    "    for doc in list_of_docs:\n",
    "        # Convert all letters to lowercase\n",
    "        doc = doc.lower()\n",
    "        #-------------------\n",
    "        chars = re.findall('[^a-zA-Z0-9 ]', doc) # Find all non-alphanumeric characters (except whitespace)\n",
    "        non_alpha = len(chars)/len(doc) # Calculate a Normalized Ratio of the number of non-alphanumeric characters to the length of the entire text passage\n",
    "        non_alpha_char_l.append(non_alpha) # Append this ratio to the previously generated list\n",
    "        #-------------------------------\n",
    "        num_chars = re.findall('\\d', doc) # Find all decimal digit characters\n",
    "        numbers_norm = len(num_chars)/len(doc) # Calculate the normalized ratio to the length of the entire text passage\n",
    "        numbers_norm_l.append(numbers_norm) # Append the calculated ratio to previously generated list\n",
    "        #------------------------------\n",
    "        toks = nltk.word_tokenize(doc) # Generate word tokens for each text passage using nltk.tokenize.word_tokenize\n",
    "        num_toks = len(toks) # Count the number of tokens\n",
    "        num_toks_l.append(num_toks) # Append the token count to previously generated list\n",
    "        #------------------------------\n",
    "        temp_list = [] # Create an empty temporary list\n",
    "        # For each token created from word_tokenize\n",
    "        for tok in toks:\n",
    "            # Determine the length of the token, and append that length to the temporary list\n",
    "            temp_list.append(len(tok))\n",
    "            \n",
    "        # Find the average token length\n",
    "        avg_tok = sum(temp_list)/len(temp_list)\n",
    "        # Append the average token length to previously generated list\n",
    "        avg_tok_len_l.append(avg_tok)\n",
    "        # Find the maximum token length\n",
    "        max_t = max(temp_list)\n",
    "        # Append the maximum token length to previously generated list\n",
    "        max_tok_len_l.append(max_t)\n",
    "        #------------------------------\n",
    "        s1= set(toks) # Generate a set of tokens from previously made list of tokens\n",
    "        num_d_c = len(s1.intersection(s2)) # Calculate the number of words that are also contained in the set of 'simple words' made previously\n",
    "        d_c_norm = num_d_c/num_toks # Normalize the value to the total number of tokens\n",
    "        d_c_norm_l.append(d_c_norm) # Append that normalized value to previously generated list\n",
    "        #------------------------------\n",
    "        \n",
    "    # Generate an array of new features which can be added to the dataframe\n",
    "    new_features = np.vstack(( np.asarray(d_c_norm_l), np.asarray(num_toks_l),  np.asarray(avg_tok_len_l), np.asarray(max_tok_len_l), \n",
    "                   np.asarray(numbers_norm_l), np.asarray(non_alpha_char_l) )).T\n",
    "\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ebbfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the number of a specific character within an 'original_text' column\n",
    "# This function designed to help with identifying non-alphanumeric characters as special characters\n",
    "# can have issue when using regex to search for them.\n",
    "def count_num_of_specific_char(text, char_of_interest):\n",
    "    # Reformat non-alphanumeric character as a set contained in brackets\n",
    "    reformat_char = '[' + char_of_interest + ']'\n",
    "    # Find all occurences of the character in a text, and count the total number of them\n",
    "    num_specific_char = len(re.findall(reformat_char, text))\n",
    "    # Return the total count of the non-alphanumeric characters\n",
    "    return num_specific_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e9e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the total number of non-whitespace characters\n",
    "def count_num_of_non_ws(text):\n",
    "    # Replace all whitespace characters with no text\n",
    "    new_string = re.sub(\"\\s\", \"\", text)\n",
    "    \n",
    "    # Return the count the length of the new non-whitespace string\n",
    "    return len(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9484aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Individual feature columns for the normalized proportion of the punctuation/non-alphanumeric characters\n",
    "def get_punctuation_features(text_data):\n",
    "    # Acquire all of the non-alphanumeric characters in a set\n",
    "    all_punctuation = set(text_data.punctuation.sum())\n",
    "    \n",
    "    # Create a new empty list to track all columns added to dataframe\n",
    "    new_columns = []\n",
    "    \n",
    "    # For each non-alphanumeric character\n",
    "    for punc_mark in all_punctuation:\n",
    "        # Create a new string for a potential column name\n",
    "        new_col_name = 'norm_' + punc_mark\n",
    "        \n",
    "        # Try to count the number of entries of the specific character, and if so, add the name of the column to the list of new column names\n",
    "        try:\n",
    "            text_data[new_col_name] = text_data.punctuation.apply(lambda x: count_num_of_specific_char(x, punc_mark))\n",
    "            text_data[new_col_name] = text_data[new_col_name] / text_data['num_non_ws_char']\n",
    "            new_columns.append(new_col_name)\n",
    "        # If there are issues, then continue to the next non-alphanumeric character\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Return the dataframe and a list of these new columns\n",
    "    return text_data, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418c23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform a text into an array of Parts-of-Speech (POS)\n",
    "def POS_preprocessing(text):\n",
    "    # Replace all non-alphanumeric or common punctuation with no text and output into a new string\n",
    "    new_string = re.sub('[^a-zA-Z0-9 ,.!;:?()]', '', text)\n",
    "    # Tokenize the new string\n",
    "    word_tokens = nltk.word_tokenize(new_string)\n",
    "    # Obtain the parts of speech tags for each of the words and put them into a list\n",
    "    pos_tag_tokens = [pair[1] for pair in nltk.pos_tag(word_tokens)]\n",
    "    # Concatenate each POS tag together into a single string\n",
    "    pos_tag_tokens = \" \".join(pos_tag_tokens)\n",
    "    # Return the single string of POS tags\n",
    "    return pos_tag_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f431b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and tokenize text\n",
    "def lemma_preprocessing(text):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43de44e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3080198/3991172524.py:8: FutureWarning: Possible nested set at position 1\n",
      "  num_specific_char = len(re.findall(reformat_char, text))\n",
      "/tmp/ipykernel_3080198/61662380.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  text_data[new_col_name] = text_data.punctuation.apply(lambda x: count_num_of_specific_char(x, punc_mark))\n",
      "/tmp/ipykernel_3080198/3442442931.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['pos_tag_tokens'] = new_text_data['original_text'].apply(lambda x: POS_preprocessing(x))\n",
      "/tmp/ipykernel_3080198/3442442931.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['num_pos_tokens'] = new_text_data['pos_tag_tokens'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_3080198/3442442931.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['lemma_text'] = new_text_data['original_text'].apply(lambda x: lemma_preprocessing(x))\n"
     ]
    }
   ],
   "source": [
    "new_text_data = preprocessing_training_data()\n",
    "d_c_list, AoA_dict, Brysbaert_dict = load_external_resource_data()\n",
    "new_text_data = get_AoA_Brysbaert_features(new_text_data)\n",
    "new_features = get_more_features(new_text_data['original_text'], d_c_list)\n",
    "new_text_data[['d_c_norm_1', 'num_toks_1', 'avg_tok_len_1', 'max_tok_len_1', 'num_char_norm_1', 'non_alphanumeric_1']] = new_features\n",
    "new_text_data['num_non_ws_char'] = new_text_data['original_text'].apply(lambda x: count_num_of_non_ws(x))\n",
    "new_text_data, punc_cols = get_punctuation_features(new_text_data)\n",
    "new_text_data['pos_tag_tokens'] = new_text_data['original_text'].apply(lambda x: POS_preprocessing(x))\n",
    "new_text_data['num_pos_tokens'] = new_text_data['pos_tag_tokens'].apply(lambda x: len(x.split()))\n",
    "new_text_data['lemma_text'] = new_text_data['original_text'].apply(lambda x: lemma_preprocessing(x))\n",
    "new_text_data = new_text_data.drop(columns=['punctuation'])\n",
    "#new_text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f5772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_X_feat(df):\n",
    "    all_features = df.columns.to_list()\n",
    "    X_feat = []\n",
    "    for feat in all_features:\n",
    "        if feat != 'label':\n",
    "            X_feat.append(feat)\n",
    "    return X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ef43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "\n",
    "def scikit_column_transformer(text_df = new_text_data, text_type = 'original_text', vector_type = 'Count', scaler='Robust', ngrams_value=1, max_features_value=None, sequence_length=500, \n",
    "                              test_size=0.2, random_state=21):\n",
    "    # Reduce the input dataframe to only include either the original_text or lemma_text columns\n",
    "    if text_type == 'original_text':\n",
    "        final_text_df = text_df.drop(columns=['lemma_text'])\n",
    "        final_text_df = final_text_df.rename(columns={'original_text': 'text'})\n",
    "    elif text_type == 'lemma_text':\n",
    "        final_text_df = text_df.drop(columns=['original_text'])\n",
    "        final_text_df = final_text_df.rename(columns={'lemma_text': 'text'})\n",
    "    else:\n",
    "        return 'Incorrect input for text_type argument'\n",
    "\n",
    "    # Perform the Train-Test Split Based on Input Data\n",
    "    X_feat = determine_X_feat(final_text_df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_text_df[X_feat], final_text_df['label'], test_size=test_size, random_state=random_state)\n",
    "  \n",
    "    # Select Vectors for text data and POS data\n",
    "    if vector_type == 'Count':\n",
    "        text_vector = CountVectorizer(ngram_range=(1, ngrams_value),max_features=max_features_value)\n",
    "        pos_vector = CountVectorizer(ngram_range=(1, ngrams_value), preprocessor=None, token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    elif vector_type == 'Tfidf':\n",
    "        text_vector = TfidfVectorizer(ngram_range=(1, ngrams_value), max_features=max_features_value)\n",
    "        pos_vector = TfidfVectorizer(ngram_range=(1, ngrams_value), token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    elif vector_type == 'Binary':\n",
    "        text_vector = CountVectorizer(binary=True, ngram_range=(1, ngrams_value),max_features=max_features_value)\n",
    "        pos_vector = CountVectorizer(binary=True, ngram_range=(1, ngrams_value), preprocessor=None, token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    else:\n",
    "        return 'Incorrect input for vector_type argument'\n",
    "\n",
    "    # Select the desired scaler based on input string\n",
    "    dict_of_scalers = {'Robust': RobustScaler(), 'MinMax': MinMaxScaler() , 'Standard': StandardScaler()}\n",
    "    try:\n",
    "        selected_feature_scaler = dict_of_scalers[scaler]\n",
    "    except:\n",
    "        return 'Incorrect input for scaler argument - must be either Count, MinMax or Standard'\n",
    "  \n",
    "    # Use Scikit-Learn Column Transformer to vectorize the text data and the POS data, and transform the additional features by selected scaler\n",
    "    column_trans = ColumnTransformer([('vector_text', text_vector, 'text'), \n",
    "                                      ('vector_pos_tags', pos_vector, 'pos_tag_tokens')], \n",
    "                                     remainder = selected_feature_scaler)\n",
    "    # Perform Fit_Transform on X_train and transform on X_test\n",
    "    X_train_matrix = column_trans.fit_transform(X_train)\n",
    "    X_test_matrix = column_trans.transform(X_test)\n",
    "\n",
    "    return column_trans, X_train_matrix, y_train, X_test_matrix, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans, X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf = scikit_column_transformer(vector_type='Tfidf')\n",
    "binary_trans, X_train_bin, y_train_bin, X_test_bin, y_test_bin = scikit_column_transformer(vector_type='Binary')\n",
    "count_trans, X_train_count, y_train_count, X_test_count, y_test_count = scikit_column_transformer(scaler='MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e043cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_results_columns = ['train_acc', 'train_precision', 'train_recall', 'train_f1', 'train_roc_auc',\n",
    "#                      'test_acc',  'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']\n",
    "\n",
    "#ML_params_columns = ['model_ID', 'alpha', 'C', 'solver']\n",
    "\n",
    "#ML_res_and_params = ML_params_columns + ML_results_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f70385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def obtain_comparison_metrics(y_true, y_pred):\n",
    "    calc_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    calc_precision = metrics.precision_score(y_true, y_pred)\n",
    "    calc_recall = metrics.recall_score(y_true, y_pred)\n",
    "    calc_f1 = metrics.f1_score(y_true, y_pred)\n",
    "    \n",
    "    return calc_accuracy, calc_precision, calc_recall, calc_f1\n",
    "\n",
    "def obtain_train_and_test_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    (calc_train_accuracy, calc_train_precision, \n",
    "     calc_train_recall, calc_train_f1) = obtain_comparison_metrics(y_train_true, y_train_pred)\n",
    "    (calc_test_accuracy, calc_test_precision, \n",
    "     calc_test_recall, calc_test_f1) = obtain_comparison_metrics(y_test_true, y_test_pred)\n",
    "    output_dict = {'train_acc': calc_train_accuracy, \n",
    "                   'train_precision': calc_train_precision, \n",
    "                   'train_recall': calc_train_recall, \n",
    "                   'train_f1': calc_train_f1, \n",
    "                   'test_acc': calc_test_accuracy, \n",
    "                   'test_precision': calc_test_precision, \n",
    "                   'test_recall': calc_test_recall, \n",
    "                   'test_f1': calc_test_f1}\n",
    "    return output_dict\n",
    "\n",
    "def obtain_roc_auc_score(clf, X, y_true):\n",
    "    y_score = clf.predict_proba(X)[:, 1]\n",
    "    roc_auc_value = metrics.roc_auc_score(y_true.values, y_score)\n",
    "    return roc_auc_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81df601",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ef59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#BernoulliNB_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for alpha_val in [0.01, 0.1, 1, 10]:\n",
    "#    model_name = 'BernoulliNB_{}'.format(str(index_val))\n",
    "#    clf = BernoulliNB(alpha=alpha_val)\n",
    "#    clf.fit(X_train_bin, y_train_bin)\n",
    "#    y_train_pred = clf.predict(X_train_bin)\n",
    "#    y_test_pred = clf.predict(X_test_bin)\n",
    "#    results_dict = obtain_train_and_test_metrics(y_train_bin, y_train_pred, y_test_bin, y_test_pred)\n",
    "#    results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_bin, y_train_bin)\n",
    "#    results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_bin, y_test_bin)\n",
    "#    results_dict['model_ID'] = model_name\n",
    "#    results_dict['alpha'] = alpha_val\n",
    "#    BernoulliNB_list.append(results_dict)\n",
    "#    index_val += 1\n",
    "    \n",
    "#ML_info_df = pd.DataFrame(data=BernoulliNB_list, columns=ML_res_and_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0745a",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19bac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for alpha_val in [0.01, 0.1, 1, 10]:\n",
    "#    model_name = 'MultinominalNB_{}'.format(str(index_val))\n",
    "#    clf = MultinomialNB(alpha=alpha_val)\n",
    "#    clf.fit(X_train_count, y_train_count)\n",
    "#    y_train_pred = clf.predict(X_train_count)\n",
    "#    y_test_pred = clf.predict(X_test_count)\n",
    "#    results_dict = obtain_train_and_test_metrics(y_train_count, y_train_pred, y_test_count, y_test_pred)\n",
    "#    results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_count, y_train_count)\n",
    "#    results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_count, y_test_count)\n",
    "#    results_dict['model_ID'] = model_name\n",
    "#    results_dict['alpha'] = alpha_val\n",
    "#    temp_ML_list.append(results_dict)\n",
    "#    index_val +=1\n",
    "    \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=ML_res_and_params)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7aa00c",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49490873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for C_val in [0.01, 0.1, 1, 10]:\n",
    "#    for solver_type in ['lbfgs', 'sag', 'saga']:\n",
    "#        model_name = \"LogReg_V{}\".format(str(index_val))\n",
    "#        clf = LogisticRegression(C=C_val, solver=solver_type, n_jobs=-1, random_state=0, max_iter=10000)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['C'] = C_val\n",
    "#        results_dict['solver'] = solver_type\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=ML_res_and_params)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f96f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization_list = ['Binary', 'Binary', 'Binary', 'Binary', \n",
    "#                      'Count', 'Count', 'Count', 'Count', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf']\n",
    "\n",
    "#ML_info_df['Vectorization'] = Vectorization_list\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08b4ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_info_df.to_csv('Current_model_information_19Feb2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f43a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results_columns = ['train_acc', 'train_precision', 'train_recall', 'train_f1', 'train_roc_auc',\n",
    "                      'test_acc',  'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']\n",
    "\n",
    "ML_params_columns = ['model_ID', 'alpha', 'C', 'solver', 'n_estimators', 'max_depth']\n",
    "\n",
    "ML_res_and_params = ML_params_columns + ML_results_columns\n",
    "#ML_info_df['n_estimators'] = np.nan\n",
    "#ML_info_df['max_depth'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2133c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0          model_ID  alpha      C solver  train_acc  \\\n",
       "0            0     BernoulliNB_0   0.01    NaN    NaN   0.684143   \n",
       "1            1     BernoulliNB_1   0.10    NaN    NaN   0.670610   \n",
       "2            2     BernoulliNB_2   1.00    NaN    NaN   0.653880   \n",
       "3            3     BernoulliNB_3  10.00    NaN    NaN   0.642958   \n",
       "4            4  MultinominalNB_0   0.01    NaN    NaN   0.745344   \n",
       "5            5  MultinominalNB_1   0.10    NaN    NaN   0.742246   \n",
       "6            6  MultinominalNB_2   1.00    NaN    NaN   0.726751   \n",
       "7            7  MultinominalNB_3  10.00    NaN    NaN   0.662967   \n",
       "8            8         LogReg_V0    NaN   0.01  lbfgs   0.666398   \n",
       "9            9         LogReg_V1    NaN   0.01    sag   0.666608   \n",
       "10          10         LogReg_V2    NaN   0.01   saga   0.666774   \n",
       "11          11         LogReg_V3    NaN   0.10  lbfgs   0.701317   \n",
       "12          12         LogReg_V4    NaN   0.10    sag   0.700111   \n",
       "13          13         LogReg_V5    NaN   0.10   saga   0.698901   \n",
       "14          14         LogReg_V6    NaN   1.00  lbfgs   0.740674   \n",
       "15          15         LogReg_V7    NaN   1.00    sag   0.726346   \n",
       "16          16         LogReg_V8    NaN   1.00   saga   0.717606   \n",
       "17          17         LogReg_V9    NaN  10.00  lbfgs   0.796704   \n",
       "18          18        LogReg_V10    NaN  10.00    sag   0.744416   \n",
       "19          19        LogReg_V11    NaN  10.00   saga   0.723847   \n",
       "\n",
       "    train_precision  train_recall  train_f1  train_roc_auc  test_acc  \\\n",
       "0          0.689154      0.669365  0.679115       0.768589  0.589341   \n",
       "1          0.676000      0.653611  0.664617       0.751843  0.609047   \n",
       "2          0.660473      0.631441  0.645631       0.729765  0.626976   \n",
       "3          0.654526      0.603514  0.627986       0.711188  0.635355   \n",
       "4          0.767017      0.703787  0.734043       0.826907  0.549178   \n",
       "5          0.763469      0.700974  0.730888       0.819968  0.561906   \n",
       "6          0.740882      0.696301  0.717900       0.796255  0.606793   \n",
       "7          0.614246      0.873781  0.721380       0.764139  0.620012   \n",
       "8          0.664549      0.670225  0.667375       0.726283  0.662458   \n",
       "9          0.664908      0.669972  0.667430       0.726320  0.662386   \n",
       "10         0.665187      0.669791  0.667481       0.726328  0.662516   \n",
       "11         0.699966      0.703303  0.701630       0.769428  0.685920   \n",
       "12         0.698899      0.701755  0.700324       0.767600  0.685559   \n",
       "13         0.697756      0.700380  0.699066       0.766192  0.685573   \n",
       "14         0.741076      0.738781  0.739927       0.816374  0.678422   \n",
       "15         0.726689      0.724424  0.725554       0.800077  0.684981   \n",
       "16         0.717540      0.716518  0.717029       0.789683  0.687321   \n",
       "17         0.796577      0.796191  0.796384       0.874830  0.632552   \n",
       "18         0.745518      0.741139  0.743322       0.820612  0.675706   \n",
       "19         0.724117      0.722058  0.723086       0.797091  0.686209   \n",
       "\n",
       "    test_precision  test_recall   test_f1  test_roc_auc Vectorization  \n",
       "0         0.586875     0.573144  0.579928      0.619243        Binary  \n",
       "1         0.607972     0.589911  0.598805      0.651346        Binary  \n",
       "2         0.627493     0.604837  0.615957      0.681550        Binary  \n",
       "3         0.641825     0.594467  0.617239      0.696557        Binary  \n",
       "4         0.546105     0.524011  0.534830      0.526223         Count  \n",
       "5         0.559498     0.537010  0.548024      0.563574         Count  \n",
       "6         0.606231     0.584857  0.595352      0.637564         Count  \n",
       "7         0.578778     0.851142  0.689021      0.714669         Count  \n",
       "8         0.657518     0.662704  0.660101      0.722717         Tfidf  \n",
       "9         0.657423     0.662704  0.660053      0.722694         Tfidf  \n",
       "10        0.657741     0.662236  0.659981      0.722632         Tfidf  \n",
       "11        0.681430     0.685371  0.683395      0.751441         Tfidf  \n",
       "12        0.681515     0.683765  0.682638      0.751067         Tfidf  \n",
       "13        0.681440     0.684028  0.682731      0.750606         Tfidf  \n",
       "14        0.675963     0.671876  0.673913      0.744277         Tfidf  \n",
       "15        0.682570     0.678682  0.680620      0.752376         Tfidf  \n",
       "16        0.684657     0.681837  0.683244      0.755119         Tfidf  \n",
       "17        0.629809     0.623591  0.626684      0.688739         Tfidf  \n",
       "18        0.673660     0.667816  0.670725      0.740492         Tfidf  \n",
       "19        0.684105     0.679149  0.681618      0.753444         Tfidf  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = pd.read_csv('Current_model_information_19Feb2023.csv')\n",
    "ML_info_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
