{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef93f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nruloff/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Modules for Data Preprocessing\n",
    "\n",
    "# Used for loading in training data [Function #1 - load_raw_training_data()]\n",
    "import pandas as pd\n",
    "# Adjust column width settings to see all of the 'original_text' column\n",
    "pd.set_option('max_colwidth', 400)\n",
    "#Adjust notebook to display all rows if output is of a large dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Used for replacing '-LRB-' and '-RRB-' with left and right parentheses in original text repectively [Function #2 - replace_LRB_and_RRB()]\n",
    "import re\n",
    "\n",
    "# Used for label value changing in preprocessing training data [Function #6 - preprocessing_training_data()]\n",
    "import numpy as np\n",
    "\n",
    "# Used for tokenization when creating score values against extraneous resourses [Function #8 - extraneous_score_calculation()]\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# Used for Parts-of-Speech tagging [Function #14 - POS_preprocessing()]\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Used for Lemmatization [Function #15 - lemma_preprocessing()]\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Used for vectorization [Function # ]\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fc3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw WikiLarge Training Data from GitHub Repository\n",
    "def load_raw_training_data():\n",
    "    # WikiLarge Training Data is very large and was split into three CSV files load each of them in.\n",
    "    textData_1 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_1.csv')\n",
    "    textData_2 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_2.csv')\n",
    "    textData_3 = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/WikiLarge_Train_part_3.csv')\n",
    "    \n",
    "    # Concatenate each of the parts together to get the original data in one dataframe\n",
    "    text_data = pd.concat([textData_1, textData_2, textData_3], ignore_index=True)\n",
    "    \n",
    "    # Return concatenated dataframe\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2998c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After searching for the first few 'original_text' entries presented in text_data.head() - it was determined\n",
    "# that '-LRB-' and '-RRB-' are left and right parentheses respectively. This function replaces those\n",
    "# text strings with their respective symbols.\n",
    "def replace_LRB_and_RRB(text):\n",
    "  # Replace the substring \"-LRB-\" with \"(\" in input string\n",
    "  new_string = re.sub(\"-LRB-\", \"(\", text)\n",
    "\n",
    "  # Replace the substring \"-RRB-\" with \")\" in new_string\n",
    "  second_string = re.sub(\"-RRB-\", \")\", new_string)\n",
    "\n",
    "  # Return the output of the second replacement\n",
    "  return second_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef1c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the finding of '-LRB-' and '-RRB-', this function replaces every character in a string that is not a parentheses with no text\n",
    "def find_parentheses(text):\n",
    "    punctuation_string = obtain_non_Alphanumeric(text)\n",
    "    new_string = re.sub(\"[^()]\", \"\", punctuation_string)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc95627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find any uneven parentheses within the 'original_text' column\n",
    "def determine_uneven_parentheses(text):\n",
    "  # Use previously generated function to find all parentheses within the 'original_text' column\n",
    "  parentheses_only = find_parentheses(text)\n",
    "\n",
    "  # Generate a list containing a single string of a closed parentheses\n",
    "  parentheses_string_list = ['()']\n",
    "\n",
    "  # While any closed parentheses exist in the parentheses column\n",
    "  while any(x in parentheses_only for x in parentheses_string_list):\n",
    "    # Replace the closed parentheses with no text\n",
    "    for paren in parentheses_string_list:\n",
    "        parentheses_only = parentheses_only.replace(paren, \"\")\n",
    "\n",
    "  # Output result as a boolean to determine if string parentheses_only has been reduce to an empty string\n",
    "  result = not parentheses_only\n",
    "\n",
    "  # Return boolean value as 0 or 1 - 0 indicating that the 'original_text' column has closed parentheses\n",
    "  if result == False:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36046154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain any non-alphanumeric characters\n",
    "def obtain_non_Alphanumeric(text):\n",
    "  # replace all non-alphanumeric characters of an input string with no text to a new output called 'new_string'\n",
    "  new_string, number_of_subs = re.subn(\"[a-zA-Z0-9]\", \"\", text)\n",
    "\n",
    "  # replace all white space characters of 'new_string' with no text to the output 'second_string'\n",
    "  second_string, second_subs = re.subn(\"\\s\", \"\", new_string)\n",
    "\n",
    "  # return 'second_string'\n",
    "  return second_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e81d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined previous functions into large preprocessing function\n",
    "\n",
    "# Additionally - find duplicate 'original_text' entries, find the mean of their label values - as some of them have\n",
    "# opposing label values - then remove all duplicates except for one with the mean label value adjusted to 0 or 1\n",
    "# based on rounding\n",
    "def preprocessing_training_data():\n",
    "    text_data = load_raw_training_data()\n",
    "    \n",
    "    # Convert binary 0 labels to -1 (this helps with keeping some of the duplicate entries by mean value calculation)\n",
    "    text_data['label'] = np.where(text_data['label'] < 1, -1, 1)\n",
    "    \n",
    "    # Separate out the duplicate entries from the individual entries - All duplicate entries are taken to \"duplicate_texts\" dataframe\n",
    "    duplicate_texts = text_data[text_data.original_text.duplicated(keep=False)].copy()\n",
    "    \n",
    "    # Individual entries can be used directly in the final version of the preprocessed dataframe\n",
    "    individual_texts = text_data[~text_data.original_text.duplicated(keep=False)].copy()\n",
    "    \n",
    "    # Group the duplicate text entries by the original text and find the mean value. \n",
    "    # If the mean value is negative, then most of the entries have been labeled as -1\n",
    "    # If the mean value is positive, then most of the entries have been labeled as 1\n",
    "    dup_group = duplicate_texts.groupby(['original_text'], as_index=False).mean()\n",
    "    \n",
    "    # Convert all positive values to 1 and all negative values to -1\n",
    "    dup_group['label'] = np.where(dup_group['label'] > 0, 1, dup_group['label'])\n",
    "    dup_group['label'] = np.where(dup_group['label'] < 0, -1, dup_group['label'])\n",
    "    \n",
    "    # If the label mean is 0, then it is an even split, and the text data cannot be used for classification\n",
    "    # Identify all rows with mean groupby label values of 0\n",
    "    zero_mean = dup_group[dup_group['label'] == 0]\n",
    "    \n",
    "    # Identify all rows with positive groupby label values\n",
    "    pos_mean = dup_group[dup_group['label'] > 0].copy()\n",
    "    \n",
    "    # Perform the same for all rows with negative groupby label values\n",
    "    neg_mean = dup_group[dup_group['label'] < 0].copy()\n",
    "    \n",
    "    # Recombine the acceptable duplicate entries with the original individual entries\n",
    "    new_text_data = pd.concat([pos_mean, neg_mean, individual_texts], ignore_index=True)\n",
    "    \n",
    "    # Convert the labels of -1 back to 0 as in the original training data\n",
    "    new_text_data['label'] = np.where(new_text_data['label'] < 0, 0, 1)\n",
    "    \n",
    "    # Replace \"-LRB-\" and \"-RRB-\" with left and right parentheses\n",
    "    new_text_data['original_text'] = new_text_data.original_text.apply(lambda x: replace_LRB_and_RRB(x))\n",
    "    \n",
    "    # Create a Column of only the punctuation using previously made function\n",
    "    new_text_data['punctuation'] = new_text_data.original_text.apply(lambda x: obtain_non_Alphanumeric(x))\n",
    "    \n",
    "    # Determine if a text entry has closed parentheses or not\n",
    "    new_text_data['closed_parentheses'] = new_text_data.original_text.apply(lambda x: determine_uneven_parentheses(x))\n",
    "    \n",
    "    return new_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130de8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which loads external resouce data provided with the WikiLarge data - those resources are:\n",
    "# 1) The Dale Chall 3000 Word List, which is one definition of words that are considered \"basic\" English.\n",
    "# 2) \"Age of Acquisition\" (AoA) estimates for about 51k English words, which refers to the approximate age (in years) when a word was learned. Early words, being more basic, have lower average AoA.\n",
    "# 3) Brysbaert et al Concreteness Ratings for 40 thousand English lemma words gathered via \n",
    "#    Amazon Mechanical Turk. The ratings come from a larger list of 63 thousand words and represent all English words known to 85% of the raters.\n",
    "\n",
    "def load_external_resource_data():\n",
    "    # Load Dale Chall word list as a list of strings\n",
    "    dale_chall = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/dale_chall.txt', header=None)\n",
    "    d_c_df = dale_chall.rename(columns={0:'words'})\n",
    "    d_c_list = d_c_df['words'].to_list()\n",
    "    \n",
    "    # Load AoA estimates for about 51 thousand English words, and return it as a dictionary\n",
    "    AoA = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/AoA_51715_words.csv', encoding='unicode_escape')\n",
    "    # Reduce the dataframe to the word and the AoA_Kup_lem score\n",
    "    AoA = AoA[['Word', 'AoA_Kup_lem']]\n",
    "    # Drop any rows where the AoA_Kup_lem score is not a value\n",
    "    AoA = AoA[AoA['AoA_Kup_lem'].notna()]\n",
    "    # Set the index of the dataframe to the words\n",
    "    AoA = AoA.set_index('Word')\n",
    "    # Take the AoA_Kup_lem score series out as a dictionary\n",
    "    AoA_dict = AoA['AoA_Kup_lem'].to_dict()\n",
    "    \n",
    "    # Load Brysbaert Concreteness ratings, and return it as a dictionary\n",
    "    Brysbaert = pd.read_csv('https://raw.githubusercontent.com/nruloff/Difficulty_Classification_of_Textual_Passages/main/Data/Concreteness_ratings_Brysbaert_et_al_BRM.txt', delimiter='\\t')\n",
    "    # Reduce the dataframe to the word and Concreteness rating\n",
    "    Brysbaert = Brysbaert[['Word','Conc.M']]\n",
    "    # Remove any words that do not have a concreteness rating\n",
    "    Brysbaert = Brysbaert[Brysbaert['Conc.M'].notna()]\n",
    "    # Set the dataframe index to the word\n",
    "    Brysbaert = Brysbaert.set_index('Word')\n",
    "    # Take the Concreteness rating series out as a dictionary\n",
    "    Brysbaert_dict = Brysbaert['Conc.M'].to_dict()\n",
    "    \n",
    "    return d_c_list, AoA_dict, Brysbaert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2f71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate a score based on values from an external resource\n",
    "def extraneous_score_calculation(text, extraneous_dict):\n",
    "    # Replace all non-alphanumeric characters with a space, then make the letters lowercase, and \n",
    "    # subsequently tokenize the words\n",
    "    tokens = nltk.word_tokenize((re.sub(\"[^a-zA-Z0-9 ]\", \" \", text)).lower())\n",
    "    # Create an empty array to add score values into\n",
    "    score_array = []\n",
    "    \n",
    "    # For each token in the tokenize 'original_text'\n",
    "    for tok in tokens:\n",
    "        # Try to find the token in the extraneous dictionary and append its score to the array\n",
    "        try:\n",
    "            ind_score = extraneous_dict[tok]\n",
    "            score_array.append(ind_score)\n",
    "        # If unable to find the token, append a value of 0 to the array\n",
    "        except:\n",
    "            score_array.append(0)\n",
    "        # Return a normalized score for the 'original_text' column by summing the scores together and dividing by \n",
    "        # the total number of tokens.\n",
    "        return np.sum(score_array)/len(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3869b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use extraneous_score_calculation function to calculate AoA and Brysbaert Concreteness Scores\n",
    "def get_AoA_Brysbaert_features(new_text_data):\n",
    "    # Calculate AoA Score using extraneous_score_calculation function\n",
    "    new_text_data['AoA_score'] = new_text_data.original_text.apply(lambda x: extraneous_score_calculation(x, AoA_dict))\n",
    "    # Calculate Brysbaert Score using extraneous_score_calculation function\n",
    "    new_text_data['Brysbaert_score'] = new_text_data.original_text.apply(lambda x: extraneous_score_calculation(x, Brysbaert_dict))\n",
    "    \n",
    "    # Convert NaN in Both 'AoA_score' and 'Brysbaert_score' columns\n",
    "    new_text_data['AoA_score'] = new_text_data['AoA_score'].fillna(0)\n",
    "    new_text_data['Brysbaert_score'] = new_text_data['Brysbaert_score'].fillna(0)\n",
    "    \n",
    "    return new_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4adecf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire additional features such as:\n",
    "# 1) Normalized proportion of word tokens from Dale Chall list in 'original_text' column\n",
    "# 2) Number of tokens in 'original_text' column\n",
    "# 3) Average length of each word token in 'original_text' column\n",
    "# 4) Largest length of a word token in 'original_text' column\n",
    "# 5) Normalized proportion of non-alphanumeric characters in 'original_text' column\n",
    "# 6) Normalized proportion of decimal digit characters in 'original_text' column\n",
    "def get_more_features(list_of_docs, easy_word_list):\n",
    "    # List for number of word tokens in text passage\n",
    "    num_toks_l = []\n",
    "    # List for number of dale_chall terms in text passage, normalized to length of text passage\n",
    "    d_c_norm_l = []\n",
    "    # Value of average word length for a textual passage\n",
    "    avg_tok_len_l = []\n",
    "    # Value of max word length for a textual passage\n",
    "    max_tok_len_l = []\n",
    "    # Number of Non-alphanumeric characters\n",
    "    non_alpha_char_l =[]\n",
    "    # Number of Characters total\n",
    "    numbers_norm_l = [] #add ratio of number charicters to total\n",
    "    # Generate a set of words based on the second input of the function (a list of words)\n",
    "    s2=set(easy_word_list)\n",
    "    \n",
    "    \n",
    "    for doc in list_of_docs:\n",
    "        # Convert all letters to lowercase\n",
    "        doc = doc.lower()\n",
    "        #-------------------\n",
    "        chars = re.findall('[^a-zA-Z0-9 ]', doc) # Find all non-alphanumeric characters (except whitespace)\n",
    "        non_alpha = len(chars)/len(doc) # Calculate a Normalized Ratio of the number of non-alphanumeric characters to the length of the entire text passage\n",
    "        non_alpha_char_l.append(non_alpha) # Append this ratio to the previously generated list\n",
    "        #-------------------------------\n",
    "        num_chars = re.findall('\\d', doc) # Find all decimal digit characters\n",
    "        numbers_norm = len(num_chars)/len(doc) # Calculate the normalized ratio to the length of the entire text passage\n",
    "        numbers_norm_l.append(numbers_norm) # Append the calculated ratio to previously generated list\n",
    "        #------------------------------\n",
    "        toks = nltk.word_tokenize(doc) # Generate word tokens for each text passage using nltk.tokenize.word_tokenize\n",
    "        num_toks = len(toks) # Count the number of tokens\n",
    "        num_toks_l.append(num_toks) # Append the token count to previously generated list\n",
    "        #------------------------------\n",
    "        temp_list = [] # Create an empty temporary list\n",
    "        # For each token created from word_tokenize\n",
    "        for tok in toks:\n",
    "            # Determine the length of the token, and append that length to the temporary list\n",
    "            temp_list.append(len(tok))\n",
    "            \n",
    "        # Find the average token length\n",
    "        avg_tok = sum(temp_list)/len(temp_list)\n",
    "        # Append the average token length to previously generated list\n",
    "        avg_tok_len_l.append(avg_tok)\n",
    "        # Find the maximum token length\n",
    "        max_t = max(temp_list)\n",
    "        # Append the maximum token length to previously generated list\n",
    "        max_tok_len_l.append(max_t)\n",
    "        #------------------------------\n",
    "        s1= set(toks) # Generate a set of tokens from previously made list of tokens\n",
    "        num_d_c = len(s1.intersection(s2)) # Calculate the number of words that are also contained in the set of 'simple words' made previously\n",
    "        d_c_norm = num_d_c/num_toks # Normalize the value to the total number of tokens\n",
    "        d_c_norm_l.append(d_c_norm) # Append that normalized value to previously generated list\n",
    "        #------------------------------\n",
    "        \n",
    "    # Generate an array of new features which can be added to the dataframe\n",
    "    new_features = np.vstack(( np.asarray(d_c_norm_l), np.asarray(num_toks_l),  np.asarray(avg_tok_len_l), np.asarray(max_tok_len_l), \n",
    "                   np.asarray(numbers_norm_l), np.asarray(non_alpha_char_l) )).T\n",
    "\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ebbfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the number of a specific character within an 'original_text' column\n",
    "# This function designed to help with identifying non-alphanumeric characters as special characters\n",
    "# can have issue when using regex to search for them.\n",
    "def count_num_of_specific_char(text, char_of_interest):\n",
    "    # Reformat non-alphanumeric character as a set contained in brackets\n",
    "    reformat_char = '[' + char_of_interest + ']'\n",
    "    # Find all occurences of the character in a text, and count the total number of them\n",
    "    num_specific_char = len(re.findall(reformat_char, text))\n",
    "    # Return the total count of the non-alphanumeric characters\n",
    "    return num_specific_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e9e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the total number of non-whitespace characters\n",
    "def count_num_of_non_ws(text):\n",
    "    # Replace all whitespace characters with no text\n",
    "    new_string = re.sub(\"\\s\", \"\", text)\n",
    "    \n",
    "    # Return the count the length of the new non-whitespace string\n",
    "    return len(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9484aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Individual feature columns for the normalized proportion of the punctuation/non-alphanumeric characters\n",
    "def get_punctuation_features(text_data):\n",
    "    # Acquire all of the non-alphanumeric characters in a set\n",
    "    all_punctuation = set(text_data.punctuation.sum())\n",
    "    \n",
    "    # Create a new empty list to track all columns added to dataframe\n",
    "    new_columns = []\n",
    "    \n",
    "    # For each non-alphanumeric character\n",
    "    for punc_mark in all_punctuation:\n",
    "        # Create a new string for a potential column name\n",
    "        new_col_name = 'norm_' + punc_mark\n",
    "        \n",
    "        # Try to count the number of entries of the specific character, and if so, add the name of the column to the list of new column names\n",
    "        try:\n",
    "            text_data[new_col_name] = text_data.punctuation.apply(lambda x: count_num_of_specific_char(x, punc_mark))\n",
    "            text_data[new_col_name] = text_data[new_col_name] / text_data['num_non_ws_char']\n",
    "            new_columns.append(new_col_name)\n",
    "        # If there are issues, then continue to the next non-alphanumeric character\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Return the dataframe and a list of these new columns\n",
    "    return text_data, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418c23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform a text into an array of Parts-of-Speech (POS)\n",
    "def POS_preprocessing(text):\n",
    "    # Replace all non-alphanumeric or common punctuation with no text and output into a new string\n",
    "    new_string = re.sub('[^a-zA-Z0-9 ,.!;:?()]', '', text)\n",
    "    # Tokenize the new string\n",
    "    word_tokens = nltk.word_tokenize(new_string)\n",
    "    # Obtain the parts of speech tags for each of the words and put them into a list\n",
    "    pos_tag_tokens = [pair[1] for pair in nltk.pos_tag(word_tokens)]\n",
    "    # Concatenate each POS tag together into a single string\n",
    "    pos_tag_tokens = \" \".join(pos_tag_tokens)\n",
    "    # Return the single string of POS tags\n",
    "    return pos_tag_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f431b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and tokenize text\n",
    "def lemma_preprocessing(text):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43de44e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624964/3991172524.py:8: FutureWarning: Possible nested set at position 1\n",
      "  num_specific_char = len(re.findall(reformat_char, text))\n",
      "/tmp/ipykernel_3624964/61662380.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  text_data[new_col_name] = text_data.punctuation.apply(lambda x: count_num_of_specific_char(x, punc_mark))\n",
      "/tmp/ipykernel_3624964/3442442931.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['pos_tag_tokens'] = new_text_data['original_text'].apply(lambda x: POS_preprocessing(x))\n",
      "/tmp/ipykernel_3624964/3442442931.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['num_pos_tokens'] = new_text_data['pos_tag_tokens'].apply(lambda x: len(x.split()))\n",
      "/tmp/ipykernel_3624964/3442442931.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_text_data['lemma_text'] = new_text_data['original_text'].apply(lambda x: lemma_preprocessing(x))\n"
     ]
    }
   ],
   "source": [
    "new_text_data = preprocessing_training_data()\n",
    "d_c_list, AoA_dict, Brysbaert_dict = load_external_resource_data()\n",
    "new_text_data = get_AoA_Brysbaert_features(new_text_data)\n",
    "new_features = get_more_features(new_text_data['original_text'], d_c_list)\n",
    "new_text_data[['d_c_norm_1', 'num_toks_1', 'avg_tok_len_1', 'max_tok_len_1', 'num_char_norm_1', 'non_alphanumeric_1']] = new_features\n",
    "new_text_data['num_non_ws_char'] = new_text_data['original_text'].apply(lambda x: count_num_of_non_ws(x))\n",
    "new_text_data, punc_cols = get_punctuation_features(new_text_data)\n",
    "new_text_data['pos_tag_tokens'] = new_text_data['original_text'].apply(lambda x: POS_preprocessing(x))\n",
    "new_text_data['num_pos_tokens'] = new_text_data['pos_tag_tokens'].apply(lambda x: len(x.split()))\n",
    "new_text_data['lemma_text'] = new_text_data['original_text'].apply(lambda x: lemma_preprocessing(x))\n",
    "new_text_data = new_text_data.drop(columns=['punctuation'])\n",
    "#new_text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e8710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f5772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_X_feat(df):\n",
    "    all_features = df.columns.to_list()\n",
    "    X_feat = []\n",
    "    for feat in all_features:\n",
    "        if feat != 'label':\n",
    "            X_feat.append(feat)\n",
    "    return X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ef43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "\n",
    "def scikit_column_transformer(text_df = new_text_data, text_type = 'original_text', vector_type = 'Count', scaler='Robust', ngrams_value=1, max_features_value=None, sequence_length=500, \n",
    "                              test_size=0.2, random_state=21):\n",
    "    # Reduce the input dataframe to only include either the original_text or lemma_text columns\n",
    "    if text_type == 'original_text':\n",
    "        final_text_df = text_df.drop(columns=['lemma_text'])\n",
    "        final_text_df = final_text_df.rename(columns={'original_text': 'text'})\n",
    "    elif text_type == 'lemma_text':\n",
    "        final_text_df = text_df.drop(columns=['original_text'])\n",
    "        final_text_df = final_text_df.rename(columns={'lemma_text': 'text'})\n",
    "    else:\n",
    "        return 'Incorrect input for text_type argument'\n",
    "\n",
    "    # Perform the Train-Test Split Based on Input Data\n",
    "    X_feat = determine_X_feat(final_text_df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_text_df[X_feat], final_text_df['label'], test_size=test_size, random_state=random_state)\n",
    "  \n",
    "    # Select Vectors for text data and POS data\n",
    "    if vector_type == 'Count':\n",
    "        text_vector = CountVectorizer(ngram_range=(1, ngrams_value),max_features=max_features_value)\n",
    "        pos_vector = CountVectorizer(ngram_range=(1, ngrams_value), preprocessor=None, token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    elif vector_type == 'Tfidf':\n",
    "        text_vector = TfidfVectorizer(ngram_range=(1, ngrams_value), max_features=max_features_value)\n",
    "        pos_vector = TfidfVectorizer(ngram_range=(1, ngrams_value), token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    elif vector_type == 'Binary':\n",
    "        text_vector = CountVectorizer(binary=True, ngram_range=(1, ngrams_value),max_features=max_features_value)\n",
    "        pos_vector = CountVectorizer(binary=True, ngram_range=(1, ngrams_value), preprocessor=None, token_pattern=r'[^\\s]+', lowercase=False)\n",
    "    else:\n",
    "        return 'Incorrect input for vector_type argument'\n",
    "\n",
    "    # Select the desired scaler based on input string\n",
    "    dict_of_scalers = {'Robust': RobustScaler(), 'MinMax': MinMaxScaler() , 'Standard': StandardScaler()}\n",
    "    try:\n",
    "        selected_feature_scaler = dict_of_scalers[scaler]\n",
    "    except:\n",
    "        return 'Incorrect input for scaler argument - must be either Count, MinMax or Standard'\n",
    "  \n",
    "    # Use Scikit-Learn Column Transformer to vectorize the text data and the POS data, and transform the additional features by selected scaler\n",
    "    column_trans = ColumnTransformer([('vector_text', text_vector, 'text'), \n",
    "                                      ('vector_pos_tags', pos_vector, 'pos_tag_tokens')], \n",
    "                                     remainder = selected_feature_scaler)\n",
    "    # Perform Fit_Transform on X_train and transform on X_test\n",
    "    X_train_matrix = column_trans.fit_transform(X_train)\n",
    "    X_test_matrix = column_trans.transform(X_test)\n",
    "\n",
    "    return column_trans, X_train_matrix, y_train, X_test_matrix, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans, X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf = scikit_column_transformer(vector_type='Tfidf')\n",
    "binary_trans, X_train_bin, y_train_bin, X_test_bin, y_test_bin = scikit_column_transformer(vector_type='Binary')\n",
    "count_trans, X_train_count, y_train_count, X_test_count, y_test_count = scikit_column_transformer(scaler='MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e043cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_results_columns = ['train_acc', 'train_precision', 'train_recall', 'train_f1', 'train_roc_auc',\n",
    "#                      'test_acc',  'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']\n",
    "\n",
    "#ML_params_columns = ['model_ID', 'alpha', 'C', 'solver']\n",
    "\n",
    "#ML_res_and_params = ML_params_columns + ML_results_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f70385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def obtain_comparison_metrics(y_true, y_pred):\n",
    "    calc_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    calc_precision = metrics.precision_score(y_true, y_pred)\n",
    "    calc_recall = metrics.recall_score(y_true, y_pred)\n",
    "    calc_f1 = metrics.f1_score(y_true, y_pred)\n",
    "    \n",
    "    return calc_accuracy, calc_precision, calc_recall, calc_f1\n",
    "\n",
    "def obtain_train_and_test_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    (calc_train_accuracy, calc_train_precision, \n",
    "     calc_train_recall, calc_train_f1) = obtain_comparison_metrics(y_train_true, y_train_pred)\n",
    "    (calc_test_accuracy, calc_test_precision, \n",
    "     calc_test_recall, calc_test_f1) = obtain_comparison_metrics(y_test_true, y_test_pred)\n",
    "    output_dict = {'train_acc': calc_train_accuracy, \n",
    "                   'train_precision': calc_train_precision, \n",
    "                   'train_recall': calc_train_recall, \n",
    "                   'train_f1': calc_train_f1, \n",
    "                   'test_acc': calc_test_accuracy, \n",
    "                   'test_precision': calc_test_precision, \n",
    "                   'test_recall': calc_test_recall, \n",
    "                   'test_f1': calc_test_f1}\n",
    "    return output_dict\n",
    "\n",
    "def obtain_roc_auc_score(clf, X, y_true):\n",
    "    y_score = clf.predict_proba(X)[:, 1]\n",
    "    roc_auc_value = metrics.roc_auc_score(y_true.values, y_score)\n",
    "    return roc_auc_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81df601",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ef59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#BernoulliNB_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for alpha_val in [0.01, 0.1, 1, 10]:\n",
    "#    model_name = 'BernoulliNB_{}'.format(str(index_val))\n",
    "#    clf = BernoulliNB(alpha=alpha_val)\n",
    "#    clf.fit(X_train_bin, y_train_bin)\n",
    "#    y_train_pred = clf.predict(X_train_bin)\n",
    "#    y_test_pred = clf.predict(X_test_bin)\n",
    "#    results_dict = obtain_train_and_test_metrics(y_train_bin, y_train_pred, y_test_bin, y_test_pred)\n",
    "#    results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_bin, y_train_bin)\n",
    "#    results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_bin, y_test_bin)\n",
    "#    results_dict['model_ID'] = model_name\n",
    "#    results_dict['alpha'] = alpha_val\n",
    "#    BernoulliNB_list.append(results_dict)\n",
    "#    index_val += 1\n",
    "    \n",
    "#ML_info_df = pd.DataFrame(data=BernoulliNB_list, columns=ML_res_and_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0745a",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19bac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for alpha_val in [0.01, 0.1, 1, 10]:\n",
    "#    model_name = 'MultinominalNB_{}'.format(str(index_val))\n",
    "#    clf = MultinomialNB(alpha=alpha_val)\n",
    "#    clf.fit(X_train_count, y_train_count)\n",
    "#    y_train_pred = clf.predict(X_train_count)\n",
    "#    y_test_pred = clf.predict(X_test_count)\n",
    "#    results_dict = obtain_train_and_test_metrics(y_train_count, y_train_pred, y_test_count, y_test_pred)\n",
    "#    results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_count, y_train_count)\n",
    "#    results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_count, y_test_count)\n",
    "#    results_dict['model_ID'] = model_name\n",
    "#    results_dict['alpha'] = alpha_val\n",
    "#    temp_ML_list.append(results_dict)\n",
    "#    index_val +=1\n",
    "    \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=ML_res_and_params)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7aa00c",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49490873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for C_val in [0.01, 0.1, 1, 10]:\n",
    "#    for solver_type in ['lbfgs', 'sag', 'saga']:\n",
    "#        model_name = \"LogReg_V{}\".format(str(index_val))\n",
    "#        clf = LogisticRegression(C=C_val, solver=solver_type, n_jobs=-1, random_state=0, max_iter=10000)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['C'] = C_val\n",
    "#        results_dict['solver'] = solver_type\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=ML_res_and_params)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f96f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization_list = ['Binary', 'Binary', 'Binary', 'Binary', \n",
    "#                      'Count', 'Count', 'Count', 'Count', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf', \n",
    "#                      'Tfidf', 'Tfidf', 'Tfidf', 'Tfidf']\n",
    "\n",
    "#ML_info_df['Vectorization'] = Vectorization_list\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08b4ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_info_df.to_csv('Current_model_information_19Feb2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f43a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results_columns = ['train_acc', 'train_precision', 'train_recall', 'train_f1', 'train_roc_auc',\n",
    "                      'test_acc',  'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']\n",
    "\n",
    "ML_params_columns = ['model_ID', 'alpha', 'C', 'solver', 'n_estimators', 'max_depth']\n",
    "\n",
    "ML_res_and_params = ML_params_columns + ML_results_columns\n",
    "#ML_info_df['n_estimators'] = np.nan\n",
    "#ML_info_df['max_depth'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2133c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_info_df = pd.read_csv('Current_model_information_19Feb2023.csv')\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6cd09",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70da302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "#clf = RandomForestClassifier(n_estimators=10, max_depth=10, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69ebe6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2d4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for n_estimators_val in tqdm([10, 100]):\n",
    "#    for max_depth_val in tqdm([10, 100]):\n",
    "#        model_name = \"Random_Forest_{}\".format(str(index_val))\n",
    "#        clf = RandomForestClassifier(n_estimators=n_estimators_val, max_depth=max_depth_val, n_jobs=-1, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['max_depth'] = max_depth_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=ML_res_and_params)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "380b0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_list = ML_info_df.columns.tolist()\n",
    "#temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e21252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_info_df = ML_info_df.drop(columns=[temp_list[0]])\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8eaba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_columns = ML_info_df.columns.to_list()\n",
    "#current_columns.append('learning_rate')\n",
    "#current_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2ee38",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cc5b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#temp_ML_list = []\n",
    "#index_val = 0\n",
    "\n",
    "#for n_estimators_val in tqdm([10]):\n",
    "#    for learning_rate_val in tqdm([0.01, 0.1, 1, 10]):\n",
    "#        model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "#        clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['learning_rate'] = learning_rate_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=current_columns)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81a7b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_ML_list = []\n",
    "\n",
    "#for n_estimators_val in tqdm([100]):\n",
    "#    for learning_rate_val in tqdm([0.01, 0.1, 1]):\n",
    "#        model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "#        clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['learning_rate'] = learning_rate_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=current_columns)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0617a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_ML_list = []\n",
    "\n",
    "#for n_estimators_val in tqdm([100]):\n",
    "#    for learning_rate_val in tqdm([1.01, 1.1]):\n",
    "#        model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "#        clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['learning_rate'] = learning_rate_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=current_columns)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c1fac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_ML_list = []\n",
    "\n",
    "#for n_estimators_val in tqdm([100]):\n",
    "#    for learning_rate_val in tqdm([10]):\n",
    "#        model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "#        clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['learning_rate'] = learning_rate_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=current_columns)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a2f482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_ML_list = []\n",
    "\n",
    "#for n_estimators_val in tqdm([200]):\n",
    "#    for learning_rate_val in tqdm([0.01, 0.1, 1, 10]):\n",
    "#        model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "#        clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "#        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "#        y_train_pred = clf.predict(X_train_tfidf)\n",
    "#        y_test_pred = clf.predict(X_test_tfidf)\n",
    "#        results_dict = obtain_train_and_test_metrics(y_train_tfidf, y_train_pred, y_test_tfidf, y_test_pred)\n",
    "#        results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_tfidf, y_train_tfidf)\n",
    "#        results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_tfidf, y_test_tfidf)\n",
    "#        results_dict['model_ID'] = model_name\n",
    "#        results_dict['n_estimators'] = n_estimators_val\n",
    "#        results_dict['learning_rate'] = learning_rate_val\n",
    "#        results_dict['Vectorization'] = 'Tfidf'\n",
    "#        temp_ML_list.append(results_dict)\n",
    "#        index_val += 1\n",
    "        \n",
    "#temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=current_columns)\n",
    "\n",
    "#ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "#ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1fc2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML_info_df.to_csv('Current_model_information_20Feb2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fc7dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             model_ID  alpha      C solver  train_acc  \\\n",
       "0            0        BernoulliNB_0   0.01    NaN    NaN   0.684143   \n",
       "1            1        BernoulliNB_1   0.10    NaN    NaN   0.670610   \n",
       "2            2        BernoulliNB_2   1.00    NaN    NaN   0.653880   \n",
       "3            3        BernoulliNB_3  10.00    NaN    NaN   0.642958   \n",
       "4            4     MultinominalNB_0   0.01    NaN    NaN   0.745344   \n",
       "5            5     MultinominalNB_1   0.10    NaN    NaN   0.742246   \n",
       "6            6     MultinominalNB_2   1.00    NaN    NaN   0.726751   \n",
       "7            7     MultinominalNB_3  10.00    NaN    NaN   0.662967   \n",
       "8            8            LogReg_V0    NaN   0.01  lbfgs   0.666398   \n",
       "9            9            LogReg_V1    NaN   0.01    sag   0.666608   \n",
       "10          10            LogReg_V2    NaN   0.01   saga   0.666774   \n",
       "11          11            LogReg_V3    NaN   0.10  lbfgs   0.701317   \n",
       "12          12            LogReg_V4    NaN   0.10    sag   0.700111   \n",
       "13          13            LogReg_V5    NaN   0.10   saga   0.698901   \n",
       "14          14            LogReg_V6    NaN   1.00  lbfgs   0.740674   \n",
       "15          15            LogReg_V7    NaN   1.00    sag   0.726346   \n",
       "16          16            LogReg_V8    NaN   1.00   saga   0.717606   \n",
       "17          17            LogReg_V9    NaN  10.00  lbfgs   0.796704   \n",
       "18          18           LogReg_V10    NaN  10.00    sag   0.744416   \n",
       "19          19           LogReg_V11    NaN  10.00   saga   0.723847   \n",
       "20          20      Random_Forest_0    NaN    NaN    NaN   0.632834   \n",
       "21          21      Random_Forest_1    NaN    NaN    NaN   0.852101   \n",
       "22          22      Random_Forest_2    NaN    NaN    NaN   0.659630   \n",
       "23          23      Random_Forest_3    NaN    NaN    NaN   0.894421   \n",
       "24          24   Gradient_Boosted_0    NaN    NaN    NaN   0.640726   \n",
       "25          25   Gradient_Boosted_1    NaN    NaN    NaN   0.654949   \n",
       "26          26   Gradient_Boosted_2    NaN    NaN    NaN   0.674084   \n",
       "27          27   Gradient_Boosted_3    NaN    NaN    NaN   0.444314   \n",
       "28          28   Gradient_Boosted_4    NaN    NaN    NaN   0.655790   \n",
       "29          29   Gradient_Boosted_5    NaN    NaN    NaN   0.681900   \n",
       "30          30   Gradient_Boosted_6    NaN    NaN    NaN   0.709140   \n",
       "31          31   Gradient_Boosted_7    NaN    NaN    NaN   0.710028   \n",
       "32          32   Gradient_Boosted_8    NaN    NaN    NaN   0.709703   \n",
       "33          33   Gradient_Boosted_9    NaN    NaN    NaN   0.444314   \n",
       "34          34  Gradient_Boosted_10    NaN    NaN    NaN   0.662599   \n",
       "35          35  Gradient_Boosted_11    NaN    NaN    NaN   0.690778   \n",
       "36          36  Gradient_Boosted_12    NaN    NaN    NaN   0.722984   \n",
       "37          37  Gradient_Boosted_13    NaN    NaN    NaN   0.444314   \n",
       "\n",
       "    train_precision  train_recall  train_f1  train_roc_auc  test_acc  \\\n",
       "0          0.689154      0.669365  0.679115       0.768589  0.589341   \n",
       "1          0.676000      0.653611  0.664617       0.751843  0.609047   \n",
       "2          0.660473      0.631441  0.645631       0.729765  0.626976   \n",
       "3          0.654526      0.603514  0.627986       0.711188  0.635355   \n",
       "4          0.767017      0.703787  0.734043       0.826907  0.549178   \n",
       "5          0.763469      0.700974  0.730888       0.819968  0.561906   \n",
       "6          0.740882      0.696301  0.717900       0.796255  0.606793   \n",
       "7          0.614246      0.873781  0.721380       0.764139  0.620012   \n",
       "8          0.664549      0.670225  0.667375       0.726283  0.662458   \n",
       "9          0.664908      0.669972  0.667430       0.726320  0.662386   \n",
       "10         0.665187      0.669791  0.667481       0.726328  0.662516   \n",
       "11         0.699966      0.703303  0.701630       0.769428  0.685920   \n",
       "12         0.698899      0.701755  0.700324       0.767600  0.685559   \n",
       "13         0.697756      0.700380  0.699066       0.766192  0.685573   \n",
       "14         0.741076      0.738781  0.739927       0.816374  0.678422   \n",
       "15         0.726689      0.724424  0.725554       0.800077  0.684981   \n",
       "16         0.717540      0.716518  0.717029       0.789683  0.687321   \n",
       "17         0.796577      0.796191  0.796384       0.874830  0.632552   \n",
       "18         0.745518      0.741139  0.743322       0.820612  0.675706   \n",
       "19         0.724117      0.722058  0.723086       0.797091  0.686209   \n",
       "20         0.617492      0.695556  0.654203       0.683249  0.630804   \n",
       "21         0.842257      0.865998  0.853963       0.931401  0.646465   \n",
       "22         0.641422      0.721950  0.679308       0.718871  0.652128   \n",
       "23         0.892141      0.897007  0.894568       0.963894  0.662082   \n",
       "24         0.648237      0.613300  0.630285       0.695334  0.640773   \n",
       "25         0.641138      0.701791  0.670095       0.713152  0.653298   \n",
       "26         0.663087      0.706037  0.683888       0.740512  0.673755   \n",
       "27         0.416136      0.279989  0.334749       0.444095  0.447080   \n",
       "28         0.641274      0.705089  0.671669       0.714714  0.653905   \n",
       "29         0.672092      0.708742  0.689931       0.751177  0.679029   \n",
       "30         0.702284      0.724742  0.713336       0.786520  0.696582   \n",
       "31         0.704347      0.722601  0.713357       0.787408  0.696596   \n",
       "32         0.704716      0.720554  0.712547       0.786444  0.696827   \n",
       "33         0.416136      0.279989  0.334749       0.444095  0.447080   \n",
       "34         0.651013      0.699021  0.674163       0.724507  0.661735   \n",
       "35         0.681064      0.716055  0.698121       0.763517  0.686758   \n",
       "36         0.717358      0.734709  0.725930       0.803206  0.697579   \n",
       "37         0.416136      0.279989  0.334749       0.444095  0.447080   \n",
       "\n",
       "    test_precision  test_recall   test_f1  test_roc_auc Vectorization  \\\n",
       "0         0.586875     0.573144  0.579928      0.619243        Binary   \n",
       "1         0.607972     0.589911  0.598805      0.651346        Binary   \n",
       "2         0.627493     0.604837  0.615957      0.681550        Binary   \n",
       "3         0.641825     0.594467  0.617239      0.696557        Binary   \n",
       "4         0.546105     0.524011  0.534830      0.526223         Count   \n",
       "5         0.559498     0.537010  0.548024      0.563574         Count   \n",
       "6         0.606231     0.584857  0.595352      0.637564         Count   \n",
       "7         0.578778     0.851142  0.689021      0.714669         Count   \n",
       "8         0.657518     0.662704  0.660101      0.722717         Tfidf   \n",
       "9         0.657423     0.662704  0.660053      0.722694         Tfidf   \n",
       "10        0.657741     0.662236  0.659981      0.722632         Tfidf   \n",
       "11        0.681430     0.685371  0.683395      0.751441         Tfidf   \n",
       "12        0.681515     0.683765  0.682638      0.751067         Tfidf   \n",
       "13        0.681440     0.684028  0.682731      0.750606         Tfidf   \n",
       "14        0.675963     0.671876  0.673913      0.744277         Tfidf   \n",
       "15        0.682570     0.678682  0.680620      0.752376         Tfidf   \n",
       "16        0.684657     0.681837  0.683244      0.755119         Tfidf   \n",
       "17        0.629809     0.623591  0.626684      0.688739         Tfidf   \n",
       "18        0.673660     0.667816  0.670725      0.740492         Tfidf   \n",
       "19        0.684105     0.679149  0.681618      0.753444         Tfidf   \n",
       "20        0.611932     0.692995  0.649946      0.678526           NaN   \n",
       "21        0.634934     0.670970  0.652455      0.708200           NaN   \n",
       "22        0.631647     0.711632  0.669258      0.711267           NaN   \n",
       "23        0.649276     0.688877  0.668490      0.729804           NaN   \n",
       "24        0.644312     0.610942  0.627183      0.694319         Tfidf   \n",
       "25        0.636538     0.696968  0.665384      0.713143         Tfidf   \n",
       "26        0.659993     0.702021  0.680359      0.740950         Tfidf   \n",
       "27        0.413997     0.283899  0.336822      0.445331         Tfidf   \n",
       "28        0.636385     0.700444  0.666880      0.714708         Tfidf   \n",
       "29        0.666215     0.703482  0.684341      0.749778         Tfidf   \n",
       "30        0.687157     0.709558  0.698178      0.769949         Tfidf   \n",
       "31        0.688434     0.706111  0.697161      0.771293         Tfidf   \n",
       "32        0.689548     0.703949  0.696674      0.768681         Tfidf   \n",
       "33        0.413997     0.283899  0.336822      0.445331         Tfidf   \n",
       "34        0.647003     0.695537  0.670392      0.724536         Tfidf   \n",
       "35        0.674024     0.710054  0.691570      0.759933         Tfidf   \n",
       "36        0.689662     0.706403  0.697932      0.772152         Tfidf   \n",
       "37        0.413997     0.283899  0.336822      0.445331         Tfidf   \n",
       "\n",
       "    n_estimators  max_depth  learning_rate  \n",
       "0            NaN        NaN            NaN  \n",
       "1            NaN        NaN            NaN  \n",
       "2            NaN        NaN            NaN  \n",
       "3            NaN        NaN            NaN  \n",
       "4            NaN        NaN            NaN  \n",
       "5            NaN        NaN            NaN  \n",
       "6            NaN        NaN            NaN  \n",
       "7            NaN        NaN            NaN  \n",
       "8            NaN        NaN            NaN  \n",
       "9            NaN        NaN            NaN  \n",
       "10           NaN        NaN            NaN  \n",
       "11           NaN        NaN            NaN  \n",
       "12           NaN        NaN            NaN  \n",
       "13           NaN        NaN            NaN  \n",
       "14           NaN        NaN            NaN  \n",
       "15           NaN        NaN            NaN  \n",
       "16           NaN        NaN            NaN  \n",
       "17           NaN        NaN            NaN  \n",
       "18           NaN        NaN            NaN  \n",
       "19           NaN        NaN            NaN  \n",
       "20          10.0       10.0            NaN  \n",
       "21          10.0      100.0            NaN  \n",
       "22         100.0       10.0            NaN  \n",
       "23         100.0      100.0            NaN  \n",
       "24          10.0        NaN           0.01  \n",
       "25          10.0        NaN           0.10  \n",
       "26          10.0        NaN           1.00  \n",
       "27          10.0        NaN          10.00  \n",
       "28         100.0        NaN           0.01  \n",
       "29         100.0        NaN           0.10  \n",
       "30         100.0        NaN           1.00  \n",
       "31         100.0        NaN           1.01  \n",
       "32         100.0        NaN           1.10  \n",
       "33         100.0        NaN          10.00  \n",
       "34         200.0        NaN           0.01  \n",
       "35         200.0        NaN           0.10  \n",
       "36         200.0        NaN           1.00  \n",
       "37         200.0        NaN          10.00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = pd.read_csv('Current_model_information_20Feb2023.csv')\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "feacdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans_2, X_train_tfidf_2, y_train_tfidf_2, X_test_tfidf_2, y_test_tfidf_2 = scikit_column_transformer(vector_type='Tfidf', ngrams_value=2)\n",
    "binary_trans_2, X_train_bin_2, y_train_bin_2, X_test_bin_2, y_test_bin_2 = scikit_column_transformer(vector_type='Binary', ngrams_value=2)\n",
    "count_trans_2, X_train_count_2, y_train_count_2, X_test_count_2, y_test_count_2 = scikit_column_transformer(scaler='MinMax', ngrams_value=2)\n",
    "\n",
    "tfidf_trans_3, X_train_tfidf_3, y_train_tfidf_3, X_test_tfidf_3, y_test_tfidf_3 = scikit_column_transformer(vector_type='Tfidf', ngrams_value=3)\n",
    "binary_trans_3, X_train_bin_3, y_train_bin_3, X_test_bin_3, y_test_bin_3 = scikit_column_transformer(vector_type='Binary', ngrams_value=3)\n",
    "count_trans_3, X_train_count_3, y_train_count_3, X_test_count_3, y_test_count_3 = scikit_column_transformer(scaler='MinMax', ngrams_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61305c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "36  Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "32   Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "31   Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "30   Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "16            LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "35  Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "19           LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "11            LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "13            LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "12            LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "15            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "29   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "14            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "18           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "26   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "10            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "8             LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "9             LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "23      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "34  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "28   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "25   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "22      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "21      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "24   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "3         BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "17            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "20      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "2         BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "7      MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "1         BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "6      MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "0         BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "5      MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "4      MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "33   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "27   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "37  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "36      0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "32      0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "31      0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "30      0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "16      0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "35      0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "19      0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "11      0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "13      0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "12      0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "15      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "29      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "14      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "18      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "26      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "10      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "8       0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "9       0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "23      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "34      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "28      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "25      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "22      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "21      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "24      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "3       0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "17      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "20      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "2       0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "7       0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "1       0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "6       0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "0       0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "5       0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "4       0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "33      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "27      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "37      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "36     0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "32     0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "31     0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "30     0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "16     0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "35     0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "19     0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "11     0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "13     0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "12     0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "15     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "29     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "14     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "18     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "26     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "10     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "8      0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "9      0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "23     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "34     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "28     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "25     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "22     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "21     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "24     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "3      0.594467  0.617239      0.696557        Binary           NaN   \n",
       "17     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "20     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "2      0.604837  0.615957      0.681550        Binary           NaN   \n",
       "7      0.851142  0.689021      0.714669         Count           NaN   \n",
       "1      0.589911  0.598805      0.651346        Binary           NaN   \n",
       "6      0.584857  0.595352      0.637564         Count           NaN   \n",
       "0      0.573144  0.579928      0.619243        Binary           NaN   \n",
       "5      0.537010  0.548024      0.563574         Count           NaN   \n",
       "4      0.524011  0.534830      0.526223         Count           NaN   \n",
       "33     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "27     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "37     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "36        NaN           1.00           1  \n",
       "32        NaN           1.10           1  \n",
       "31        NaN           1.01           1  \n",
       "30        NaN           1.00           1  \n",
       "16        NaN            NaN           1  \n",
       "35        NaN           0.10           1  \n",
       "19        NaN            NaN           1  \n",
       "11        NaN            NaN           1  \n",
       "13        NaN            NaN           1  \n",
       "12        NaN            NaN           1  \n",
       "15        NaN            NaN           1  \n",
       "29        NaN           0.10           1  \n",
       "14        NaN            NaN           1  \n",
       "18        NaN            NaN           1  \n",
       "26        NaN           1.00           1  \n",
       "10        NaN            NaN           1  \n",
       "8         NaN            NaN           1  \n",
       "9         NaN            NaN           1  \n",
       "23      100.0            NaN           1  \n",
       "34        NaN           0.01           1  \n",
       "28        NaN           0.01           1  \n",
       "25        NaN           0.10           1  \n",
       "22       10.0            NaN           1  \n",
       "21      100.0            NaN           1  \n",
       "24        NaN           0.01           1  \n",
       "3         NaN            NaN           1  \n",
       "17        NaN            NaN           1  \n",
       "20       10.0            NaN           1  \n",
       "2         NaN            NaN           1  \n",
       "7         NaN            NaN           1  \n",
       "1         NaN            NaN           1  \n",
       "6         NaN            NaN           1  \n",
       "0         NaN            NaN           1  \n",
       "5         NaN            NaN           1  \n",
       "4         NaN            NaN           1  \n",
       "33        NaN          10.00           1  \n",
       "27        NaN          10.00           1  \n",
       "37        NaN          10.00           1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = pd.read_csv('Current_model_information_20Feb2023.csv')\n",
    "temp_list = ML_info_df.columns.tolist()\n",
    "ML_info_df = ML_info_df.drop(columns=[temp_list[0]])\n",
    "ML_info_df['ngrams_val'] = 1\n",
    "ML_info_df = ML_info_df.sort_values(['test_acc'], ascending=False)\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c4f085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_ID',\n",
       " 'alpha',\n",
       " 'C',\n",
       " 'solver',\n",
       " 'train_acc',\n",
       " 'train_precision',\n",
       " 'train_recall',\n",
       " 'train_f1',\n",
       " 'train_roc_auc',\n",
       " 'test_acc',\n",
       " 'test_precision',\n",
       " 'test_recall',\n",
       " 'test_f1',\n",
       " 'test_roc_auc',\n",
       " 'Vectorization',\n",
       " 'n_estimators',\n",
       " 'max_depth',\n",
       " 'learning_rate',\n",
       " 'ngrams_val']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = ML_info_df.columns.to_list()\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6df1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [52:58<1:45:56, 3178.34s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [1:43:56<51:47, 3107.90s/it]\u001b[A\n",
      "100%|██████████| 3/3 [2:33:50<00:00, 3076.77s/it]\u001b[A\n",
      "100%|██████████| 1/1 [2:33:50<00:00, 9230.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "0   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "1    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "2    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "3    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "4             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "5   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "6            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "7             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "8             LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "9             LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "10            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "11   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "12            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "13           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "14   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "15            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "16            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "17            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "18      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "19  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "20   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "21   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "22      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "23      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "24   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "25        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "26            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "27      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "28        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "29     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "30        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "31     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "32        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "33     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "34     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "35   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "36   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "37  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "38  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "39  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "40  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "41  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "42  Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "43  Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "0       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "1       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "2       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "3       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "4       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "5       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "6       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "7       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "8       0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "9       0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "10      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "11      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "12      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "13      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "14      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "15      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "16      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "17      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "18      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "19      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "20      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "21      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "22      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "23      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "24      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "25      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "26      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "27      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "28      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "29      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "30      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "31      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "32      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "33      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "34      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "35      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "36      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "37      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "38      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "39      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "40      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "41      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "42      0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "43      0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "0      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "1      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "2      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "3      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "4      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "5      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "6      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "7      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "8      0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "9      0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "10     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "11     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "12     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "13     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "14     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "15     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "16     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "17     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "18     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "19     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "20     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "21     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "22     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "23     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "24     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "25     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "26     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "27     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "28     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "29     0.851142  0.689021      0.714669         Count           NaN   \n",
       "30     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "31     0.584857  0.595352      0.637564         Count           NaN   \n",
       "32     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "33     0.537010  0.548024      0.563574         Count           NaN   \n",
       "34     0.524011  0.534830      0.526223         Count           NaN   \n",
       "35     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "36     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "37     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "38     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "39     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "40     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "41     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "42     0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "43     0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "0         NaN           1.00           1  \n",
       "1         NaN           1.10           1  \n",
       "2         NaN           1.01           1  \n",
       "3         NaN           1.00           1  \n",
       "4         NaN            NaN           1  \n",
       "5         NaN           0.10           1  \n",
       "6         NaN            NaN           1  \n",
       "7         NaN            NaN           1  \n",
       "8         NaN            NaN           1  \n",
       "9         NaN            NaN           1  \n",
       "10        NaN            NaN           1  \n",
       "11        NaN           0.10           1  \n",
       "12        NaN            NaN           1  \n",
       "13        NaN            NaN           1  \n",
       "14        NaN           1.00           1  \n",
       "15        NaN            NaN           1  \n",
       "16        NaN            NaN           1  \n",
       "17        NaN            NaN           1  \n",
       "18      100.0            NaN           1  \n",
       "19        NaN           0.01           1  \n",
       "20        NaN           0.01           1  \n",
       "21        NaN           0.10           1  \n",
       "22       10.0            NaN           1  \n",
       "23      100.0            NaN           1  \n",
       "24        NaN           0.01           1  \n",
       "25        NaN            NaN           1  \n",
       "26        NaN            NaN           1  \n",
       "27       10.0            NaN           1  \n",
       "28        NaN            NaN           1  \n",
       "29        NaN            NaN           1  \n",
       "30        NaN            NaN           1  \n",
       "31        NaN            NaN           1  \n",
       "32        NaN            NaN           1  \n",
       "33        NaN            NaN           1  \n",
       "34        NaN            NaN           1  \n",
       "35        NaN          10.00           1  \n",
       "36        NaN          10.00           1  \n",
       "37        NaN          10.00           1  \n",
       "38        NaN           0.01           0  \n",
       "39        NaN           0.01           1  \n",
       "40        NaN           0.10           0  \n",
       "41        NaN           0.10           1  \n",
       "42        NaN           1.00           0  \n",
       "43        NaN           1.00           1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "temp_ML_list = []\n",
    "index_val = 14\n",
    "tfidf_ngram_test_tuples = [(X_train_tfidf_2, y_train_tfidf_2, X_test_tfidf_2, y_test_tfidf_2),\n",
    "                           (X_train_tfidf_3, y_train_tfidf_3, X_test_tfidf_3, y_test_tfidf_3)]\n",
    "\n",
    "for n_estimators_val in tqdm([100]):\n",
    "    for learning_rate_val in tqdm([0.01, 0.1, 1]):\n",
    "        for ngrams_tuple_val in np.arange(2):\n",
    "            ngrams_tuple = tfidf_ngram_test_tuples[ngrams_tuple_val]\n",
    "            X_train_temp = ngrams_tuple[0]\n",
    "            y_train_temp = ngrams_tuple[1]\n",
    "            X_test_temp = ngrams_tuple[2]\n",
    "            y_test_temp = ngrams_tuple[3]\n",
    "            model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "            clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "            clf.fit(X_train_temp, y_train_temp)\n",
    "            y_train_pred = clf.predict(X_train_temp)\n",
    "            y_test_pred = clf.predict(X_test_temp)\n",
    "            results_dict = obtain_train_and_test_metrics(y_train_temp, y_train_pred, y_test_temp, y_test_pred)\n",
    "            results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_temp, y_train_temp)\n",
    "            results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_temp, y_test_temp)\n",
    "            results_dict['model_ID'] = model_name\n",
    "            results_dict['n_estimators'] = n_estimators_val\n",
    "            results_dict['learning_rate'] = learning_rate_val\n",
    "            results_dict['Vectorization'] = 'Tfidf'\n",
    "            results_dict['ngrams_val'] = ngrams_tuple_val\n",
    "            temp_ML_list.append(results_dict)\n",
    "            index_val += 1\n",
    "        \n",
    "temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=all_columns)\n",
    "\n",
    "ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a14027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "43  Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "42  Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "0   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "1    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "2    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "3    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "4             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "5   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "6            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "7             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "8             LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "9             LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "10            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "41  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "40  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "11   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "12            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "13           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "14   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "15            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "16            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "17            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "18      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "19  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "39  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "38  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "20   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "21   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "22      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "23      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "24   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "25        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "26            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "27      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "28        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "29     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "30        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "31     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "32        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "33     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "34     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "35   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "36   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "37  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "43      0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "42      0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "0       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "1       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "2       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "3       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "4       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "5       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "6       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "7       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "8       0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "9       0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "10      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "41      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "40      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "11      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "12      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "13      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "14      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "15      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "16      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "17      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "18      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "19      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "39      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "38      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "20      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "21      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "22      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "23      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "24      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "25      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "26      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "27      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "28      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "29      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "30      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "31      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "32      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "33      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "34      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "35      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "36      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "37      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "43     0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "42     0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "0      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "1      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "2      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "3      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "4      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "5      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "6      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "7      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "8      0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "9      0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "10     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "41     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "40     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "11     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "12     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "13     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "14     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "15     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "16     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "17     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "18     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "19     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "39     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "38     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "20     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "21     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "22     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "23     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "24     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "25     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "26     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "27     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "28     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "29     0.851142  0.689021      0.714669         Count           NaN   \n",
       "30     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "31     0.584857  0.595352      0.637564         Count           NaN   \n",
       "32     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "33     0.537010  0.548024      0.563574         Count           NaN   \n",
       "34     0.524011  0.534830      0.526223         Count           NaN   \n",
       "35     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "36     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "37     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "43        NaN           1.00           1  \n",
       "42        NaN           1.00           0  \n",
       "0         NaN           1.00           1  \n",
       "1         NaN           1.10           1  \n",
       "2         NaN           1.01           1  \n",
       "3         NaN           1.00           1  \n",
       "4         NaN            NaN           1  \n",
       "5         NaN           0.10           1  \n",
       "6         NaN            NaN           1  \n",
       "7         NaN            NaN           1  \n",
       "8         NaN            NaN           1  \n",
       "9         NaN            NaN           1  \n",
       "10        NaN            NaN           1  \n",
       "41        NaN           0.10           1  \n",
       "40        NaN           0.10           0  \n",
       "11        NaN           0.10           1  \n",
       "12        NaN            NaN           1  \n",
       "13        NaN            NaN           1  \n",
       "14        NaN           1.00           1  \n",
       "15        NaN            NaN           1  \n",
       "16        NaN            NaN           1  \n",
       "17        NaN            NaN           1  \n",
       "18      100.0            NaN           1  \n",
       "19        NaN           0.01           1  \n",
       "39        NaN           0.01           1  \n",
       "38        NaN           0.01           0  \n",
       "20        NaN           0.01           1  \n",
       "21        NaN           0.10           1  \n",
       "22       10.0            NaN           1  \n",
       "23      100.0            NaN           1  \n",
       "24        NaN           0.01           1  \n",
       "25        NaN            NaN           1  \n",
       "26        NaN            NaN           1  \n",
       "27       10.0            NaN           1  \n",
       "28        NaN            NaN           1  \n",
       "29        NaN            NaN           1  \n",
       "30        NaN            NaN           1  \n",
       "31        NaN            NaN           1  \n",
       "32        NaN            NaN           1  \n",
       "33        NaN            NaN           1  \n",
       "34        NaN            NaN           1  \n",
       "35        NaN          10.00           1  \n",
       "36        NaN          10.00           1  \n",
       "37        NaN          10.00           1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = ML_info_df.sort_values(['test_acc'], ascending=False)\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3bd0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB_3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_V9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB_2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinominalNB_3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB_1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinominalNB_2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB_0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinominalNB_1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinominalNB_0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     alpha      C solver  train_acc  train_precision  \\\n",
       "model_ID                                                               \n",
       "Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "Gradient_Boosted_8     NaN    NaN    NaN   0.709703         0.704716   \n",
       "Gradient_Boosted_7     NaN    NaN    NaN   0.710028         0.704347   \n",
       "Gradient_Boosted_6     NaN    NaN    NaN   0.709140         0.702284   \n",
       "LogReg_V8              NaN   1.00   saga   0.717606         0.717540   \n",
       "Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "LogReg_V11             NaN  10.00   saga   0.723847         0.724117   \n",
       "LogReg_V3              NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "LogReg_V5              NaN   0.10   saga   0.698901         0.697756   \n",
       "LogReg_V4              NaN   0.10    sag   0.700111         0.698899   \n",
       "LogReg_V7              NaN   1.00    sag   0.726346         0.726689   \n",
       "Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "Gradient_Boosted_5     NaN    NaN    NaN   0.681900         0.672092   \n",
       "LogReg_V6              NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "LogReg_V10             NaN  10.00    sag   0.744416         0.745518   \n",
       "Gradient_Boosted_2     NaN    NaN    NaN   0.674084         0.663087   \n",
       "LogReg_V2              NaN   0.01   saga   0.666774         0.665187   \n",
       "LogReg_V0              NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "LogReg_V1              NaN   0.01    sag   0.666608         0.664908   \n",
       "Random_Forest_3        NaN    NaN    NaN   0.894421         0.892141   \n",
       "Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "Gradient_Boosted_4     NaN    NaN    NaN   0.655790         0.641274   \n",
       "Gradient_Boosted_1     NaN    NaN    NaN   0.654949         0.641138   \n",
       "Random_Forest_2        NaN    NaN    NaN   0.659630         0.641422   \n",
       "Random_Forest_1        NaN    NaN    NaN   0.852101         0.842257   \n",
       "Gradient_Boosted_0     NaN    NaN    NaN   0.640726         0.648237   \n",
       "BernoulliNB_3        10.00    NaN    NaN   0.642958         0.654526   \n",
       "LogReg_V9              NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "Random_Forest_0        NaN    NaN    NaN   0.632834         0.617492   \n",
       "BernoulliNB_2         1.00    NaN    NaN   0.653880         0.660473   \n",
       "MultinominalNB_3     10.00    NaN    NaN   0.662967         0.614246   \n",
       "BernoulliNB_1         0.10    NaN    NaN   0.670610         0.676000   \n",
       "MultinominalNB_2      1.00    NaN    NaN   0.726751         0.740882   \n",
       "BernoulliNB_0         0.01    NaN    NaN   0.684143         0.689154   \n",
       "MultinominalNB_1      0.10    NaN    NaN   0.742246         0.763469   \n",
       "MultinominalNB_0      0.01    NaN    NaN   0.745344         0.767017   \n",
       "Gradient_Boosted_9     NaN    NaN    NaN   0.444314         0.416136   \n",
       "Gradient_Boosted_3     NaN    NaN    NaN   0.444314         0.416136   \n",
       "Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "NaN                    NaN    NaN    NaN        NaN              NaN   \n",
       "\n",
       "                     train_recall  train_f1  train_roc_auc  test_acc  \\\n",
       "model_ID                                                               \n",
       "Gradient_Boosted_19      0.735686  0.721721       0.796982  0.698908   \n",
       "Gradient_Boosted_18      0.733834  0.719540       0.794199  0.697853   \n",
       "Gradient_Boosted_12      0.734709  0.725930       0.803206  0.697579   \n",
       "Gradient_Boosted_8       0.720554  0.712547       0.786444  0.696827   \n",
       "Gradient_Boosted_7       0.722601  0.713357       0.787408  0.696596   \n",
       "Gradient_Boosted_6       0.724742  0.713336       0.786520  0.696582   \n",
       "LogReg_V8                0.716518  0.717029       0.789683  0.687321   \n",
       "Gradient_Boosted_11      0.716055  0.698121       0.763517  0.686758   \n",
       "LogReg_V11               0.722058  0.723086       0.797091  0.686209   \n",
       "LogReg_V3                0.703303  0.701630       0.769428  0.685920   \n",
       "LogReg_V5                0.700380  0.699066       0.766192  0.685573   \n",
       "LogReg_V4                0.701755  0.700324       0.767600  0.685559   \n",
       "LogReg_V7                0.724424  0.725554       0.800077  0.684981   \n",
       "Gradient_Boosted_17      0.711520  0.693499       0.756937  0.683608   \n",
       "Gradient_Boosted_16      0.707209  0.692335       0.756463  0.683579   \n",
       "Gradient_Boosted_5       0.708742  0.689931       0.751177  0.679029   \n",
       "LogReg_V6                0.738781  0.739927       0.816374  0.678422   \n",
       "LogReg_V10               0.741139  0.743322       0.820612  0.675706   \n",
       "Gradient_Boosted_2       0.706037  0.683888       0.740512  0.673755   \n",
       "LogReg_V2                0.669791  0.667481       0.726328  0.662516   \n",
       "LogReg_V0                0.670225  0.667375       0.726283  0.662458   \n",
       "LogReg_V1                0.669972  0.667430       0.726320  0.662386   \n",
       "Random_Forest_3          0.897007  0.894568       0.963894  0.662082   \n",
       "Gradient_Boosted_10      0.699021  0.674163       0.724507  0.661735   \n",
       "Gradient_Boosted_15      0.693010  0.671465       0.717713  0.659973   \n",
       "Gradient_Boosted_14      0.699643  0.672844       0.716818  0.659034   \n",
       "Gradient_Boosted_4       0.705089  0.671669       0.714714  0.653905   \n",
       "Gradient_Boosted_1       0.701791  0.670095       0.713152  0.653298   \n",
       "Random_Forest_2          0.721950  0.679308       0.718871  0.652128   \n",
       "Random_Forest_1          0.865998  0.853963       0.931401  0.646465   \n",
       "Gradient_Boosted_0       0.613300  0.630285       0.695334  0.640773   \n",
       "BernoulliNB_3            0.603514  0.627986       0.711188  0.635355   \n",
       "LogReg_V9                0.796191  0.796384       0.874830  0.632552   \n",
       "Random_Forest_0          0.695556  0.654203       0.683249  0.630804   \n",
       "BernoulliNB_2            0.631441  0.645631       0.729765  0.626976   \n",
       "MultinominalNB_3         0.873781  0.721380       0.764139  0.620012   \n",
       "BernoulliNB_1            0.653611  0.664617       0.751843  0.609047   \n",
       "MultinominalNB_2         0.696301  0.717900       0.796255  0.606793   \n",
       "BernoulliNB_0            0.669365  0.679115       0.768589  0.589341   \n",
       "MultinominalNB_1         0.700974  0.730888       0.819968  0.561906   \n",
       "MultinominalNB_0         0.703787  0.734043       0.826907  0.549178   \n",
       "Gradient_Boosted_9       0.279989  0.334749       0.444095  0.447080   \n",
       "Gradient_Boosted_3       0.279989  0.334749       0.444095  0.447080   \n",
       "Gradient_Boosted_13      0.279989  0.334749       0.444095  0.447080   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "NaN                           NaN       NaN            NaN       NaN   \n",
       "\n",
       "                     test_precision  test_recall   test_f1  test_roc_auc  \\\n",
       "model_ID                                                                   \n",
       "Gradient_Boosted_19        0.692257     0.704329  0.698241      0.774761   \n",
       "Gradient_Boosted_18        0.689334     0.708302  0.698689      0.774788   \n",
       "Gradient_Boosted_12        0.689662     0.706403  0.697932      0.772152   \n",
       "Gradient_Boosted_8         0.689548     0.703949  0.696674      0.768681   \n",
       "Gradient_Boosted_7         0.688434     0.706111  0.697161      0.771293   \n",
       "Gradient_Boosted_6         0.687157     0.709558  0.698178      0.769949   \n",
       "LogReg_V8                  0.684657     0.681837  0.683244      0.755119   \n",
       "Gradient_Boosted_11        0.674024     0.710054  0.691570      0.759933   \n",
       "LogReg_V11                 0.684105     0.679149  0.681618      0.753444   \n",
       "LogReg_V3                  0.681430     0.685371  0.683395      0.751441   \n",
       "LogReg_V5                  0.681440     0.684028  0.682731      0.750606   \n",
       "LogReg_V4                  0.681515     0.683765  0.682638      0.751067   \n",
       "LogReg_V7                  0.682570     0.678682  0.680620      0.752376   \n",
       "Gradient_Boosted_17        0.671210     0.706228  0.688274      0.755358   \n",
       "Gradient_Boosted_16        0.672466     0.702284  0.687052      0.754663   \n",
       "Gradient_Boosted_5         0.666215     0.703482  0.684341      0.749778   \n",
       "LogReg_V6                  0.675963     0.671876  0.673913      0.744277   \n",
       "LogReg_V10                 0.673660     0.667816  0.670725      0.740492   \n",
       "Gradient_Boosted_2         0.659993     0.702021  0.680359      0.740950   \n",
       "LogReg_V2                  0.657741     0.662236  0.659981      0.722632   \n",
       "LogReg_V0                  0.657518     0.662704  0.660101      0.722717   \n",
       "LogReg_V1                  0.657423     0.662704  0.660053      0.722694   \n",
       "Random_Forest_3            0.649276     0.688877  0.668490      0.729804   \n",
       "Gradient_Boosted_10        0.647003     0.695537  0.670392      0.724536   \n",
       "Gradient_Boosted_15        0.646846     0.688263  0.666912      0.717345   \n",
       "Gradient_Boosted_14        0.643794     0.695303  0.668558      0.716524   \n",
       "Gradient_Boosted_4         0.636385     0.700444  0.666880      0.714708   \n",
       "Gradient_Boosted_1         0.636538     0.696968  0.665384      0.713143   \n",
       "Random_Forest_2            0.631647     0.711632  0.669258      0.711267   \n",
       "Random_Forest_1            0.634934     0.670970  0.652455      0.708200   \n",
       "Gradient_Boosted_0         0.644312     0.610942  0.627183      0.694319   \n",
       "BernoulliNB_3              0.641825     0.594467  0.617239      0.696557   \n",
       "LogReg_V9                  0.629809     0.623591  0.626684      0.688739   \n",
       "Random_Forest_0            0.611932     0.692995  0.649946      0.678526   \n",
       "BernoulliNB_2              0.627493     0.604837  0.615957      0.681550   \n",
       "MultinominalNB_3           0.578778     0.851142  0.689021      0.714669   \n",
       "BernoulliNB_1              0.607972     0.589911  0.598805      0.651346   \n",
       "MultinominalNB_2           0.606231     0.584857  0.595352      0.637564   \n",
       "BernoulliNB_0              0.586875     0.573144  0.579928      0.619243   \n",
       "MultinominalNB_1           0.559498     0.537010  0.548024      0.563574   \n",
       "MultinominalNB_0           0.546105     0.524011  0.534830      0.526223   \n",
       "Gradient_Boosted_9         0.413997     0.283899  0.336822      0.445331   \n",
       "Gradient_Boosted_3         0.413997     0.283899  0.336822      0.445331   \n",
       "Gradient_Boosted_13        0.413997     0.283899  0.336822      0.445331   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "NaN                             NaN          NaN       NaN           NaN   \n",
       "\n",
       "                    Vectorization  n_estimators  max_depth  learning_rate  \\\n",
       "model_ID                                                                    \n",
       "Gradient_Boosted_19         Tfidf         100.0        NaN           1.00   \n",
       "Gradient_Boosted_18         Tfidf         100.0        NaN           1.00   \n",
       "Gradient_Boosted_12         Tfidf         200.0        NaN           1.00   \n",
       "Gradient_Boosted_8          Tfidf         100.0        NaN           1.10   \n",
       "Gradient_Boosted_7          Tfidf         100.0        NaN           1.01   \n",
       "Gradient_Boosted_6          Tfidf         100.0        NaN           1.00   \n",
       "LogReg_V8                   Tfidf           NaN        NaN            NaN   \n",
       "Gradient_Boosted_11         Tfidf         200.0        NaN           0.10   \n",
       "LogReg_V11                  Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V3                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V5                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V4                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V7                   Tfidf           NaN        NaN            NaN   \n",
       "Gradient_Boosted_17         Tfidf         100.0        NaN           0.10   \n",
       "Gradient_Boosted_16         Tfidf         100.0        NaN           0.10   \n",
       "Gradient_Boosted_5          Tfidf         100.0        NaN           0.10   \n",
       "LogReg_V6                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V10                  Tfidf           NaN        NaN            NaN   \n",
       "Gradient_Boosted_2          Tfidf          10.0        NaN           1.00   \n",
       "LogReg_V2                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V0                   Tfidf           NaN        NaN            NaN   \n",
       "LogReg_V1                   Tfidf           NaN        NaN            NaN   \n",
       "Random_Forest_3               NaN         100.0      100.0            NaN   \n",
       "Gradient_Boosted_10         Tfidf         200.0        NaN           0.01   \n",
       "Gradient_Boosted_15         Tfidf         100.0        NaN           0.01   \n",
       "Gradient_Boosted_14         Tfidf         100.0        NaN           0.01   \n",
       "Gradient_Boosted_4          Tfidf         100.0        NaN           0.01   \n",
       "Gradient_Boosted_1          Tfidf          10.0        NaN           0.10   \n",
       "Random_Forest_2               NaN         100.0       10.0            NaN   \n",
       "Random_Forest_1               NaN          10.0      100.0            NaN   \n",
       "Gradient_Boosted_0          Tfidf          10.0        NaN           0.01   \n",
       "BernoulliNB_3              Binary           NaN        NaN            NaN   \n",
       "LogReg_V9                   Tfidf           NaN        NaN            NaN   \n",
       "Random_Forest_0               NaN          10.0       10.0            NaN   \n",
       "BernoulliNB_2              Binary           NaN        NaN            NaN   \n",
       "MultinominalNB_3            Count           NaN        NaN            NaN   \n",
       "BernoulliNB_1              Binary           NaN        NaN            NaN   \n",
       "MultinominalNB_2            Count           NaN        NaN            NaN   \n",
       "BernoulliNB_0              Binary           NaN        NaN            NaN   \n",
       "MultinominalNB_1            Count           NaN        NaN            NaN   \n",
       "MultinominalNB_0            Count           NaN        NaN            NaN   \n",
       "Gradient_Boosted_9          Tfidf         100.0        NaN          10.00   \n",
       "Gradient_Boosted_3          Tfidf          10.0        NaN          10.00   \n",
       "Gradient_Boosted_13         Tfidf         200.0        NaN          10.00   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "NaN                           NaN           NaN        NaN            NaN   \n",
       "\n",
       "                     ngrams_val  \n",
       "model_ID                         \n",
       "Gradient_Boosted_19         1.0  \n",
       "Gradient_Boosted_18         0.0  \n",
       "Gradient_Boosted_12         1.0  \n",
       "Gradient_Boosted_8          1.0  \n",
       "Gradient_Boosted_7          1.0  \n",
       "Gradient_Boosted_6          1.0  \n",
       "LogReg_V8                   1.0  \n",
       "Gradient_Boosted_11         1.0  \n",
       "LogReg_V11                  1.0  \n",
       "LogReg_V3                   1.0  \n",
       "LogReg_V5                   1.0  \n",
       "LogReg_V4                   1.0  \n",
       "LogReg_V7                   1.0  \n",
       "Gradient_Boosted_17         1.0  \n",
       "Gradient_Boosted_16         0.0  \n",
       "Gradient_Boosted_5          1.0  \n",
       "LogReg_V6                   1.0  \n",
       "LogReg_V10                  1.0  \n",
       "Gradient_Boosted_2          1.0  \n",
       "LogReg_V2                   1.0  \n",
       "LogReg_V0                   1.0  \n",
       "LogReg_V1                   1.0  \n",
       "Random_Forest_3             1.0  \n",
       "Gradient_Boosted_10         1.0  \n",
       "Gradient_Boosted_15         1.0  \n",
       "Gradient_Boosted_14         0.0  \n",
       "Gradient_Boosted_4          1.0  \n",
       "Gradient_Boosted_1          1.0  \n",
       "Random_Forest_2             1.0  \n",
       "Random_Forest_1             1.0  \n",
       "Gradient_Boosted_0          1.0  \n",
       "BernoulliNB_3               1.0  \n",
       "LogReg_V9                   1.0  \n",
       "Random_Forest_0             1.0  \n",
       "BernoulliNB_2               1.0  \n",
       "MultinominalNB_3            1.0  \n",
       "BernoulliNB_1               1.0  \n",
       "MultinominalNB_2            1.0  \n",
       "BernoulliNB_0               1.0  \n",
       "MultinominalNB_1            1.0  \n",
       "MultinominalNB_0            1.0  \n",
       "Gradient_Boosted_9          1.0  \n",
       "Gradient_Boosted_3          1.0  \n",
       "Gradient_Boosted_13         1.0  \n",
       "NaN                         2.0  \n",
       "NaN                         3.0  \n",
       "NaN                         2.0  \n",
       "NaN                         3.0  \n",
       "NaN                         2.0  \n",
       "NaN                         3.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = ML_info_df.set_index('model_ID')\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e920c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_info_df.at['Gradient_Boosted_14', 'ngrams_val'] = 2\n",
    "ML_info_df.at['Gradient_Boosted_15', 'ngrams_val'] = 3\n",
    "ML_info_df.at['Gradient_Boosted_16', 'ngrams_val'] = 2\n",
    "ML_info_df.at['Gradient_Boosted_17', 'ngrams_val'] = 3\n",
    "ML_info_df.at['Gradient_Boosted_18', 'ngrams_val'] = 2\n",
    "ML_info_df.at['Gradient_Boosted_19', 'ngrams_val'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7add9a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Boosted_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     alpha   C solver  train_acc  train_precision  \\\n",
       "model_ID                                                            \n",
       "Gradient_Boosted_19    NaN NaN    NaN   0.716714         0.708277   \n",
       "Gradient_Boosted_18    NaN NaN    NaN   0.714348         0.705792   \n",
       "Gradient_Boosted_12    NaN NaN    NaN   0.722984         0.717358   \n",
       "Gradient_Boosted_8     NaN NaN    NaN   0.709703         0.704716   \n",
       "Gradient_Boosted_7     NaN NaN    NaN   0.710028         0.704347   \n",
       "\n",
       "                     train_recall  train_f1  train_roc_auc  test_acc  \\\n",
       "model_ID                                                               \n",
       "Gradient_Boosted_19      0.735686  0.721721       0.796982  0.698908   \n",
       "Gradient_Boosted_18      0.733834  0.719540       0.794199  0.697853   \n",
       "Gradient_Boosted_12      0.734709  0.725930       0.803206  0.697579   \n",
       "Gradient_Boosted_8       0.720554  0.712547       0.786444  0.696827   \n",
       "Gradient_Boosted_7       0.722601  0.713357       0.787408  0.696596   \n",
       "\n",
       "                     test_precision  test_recall   test_f1  test_roc_auc  \\\n",
       "model_ID                                                                   \n",
       "Gradient_Boosted_19        0.692257     0.704329  0.698241      0.774761   \n",
       "Gradient_Boosted_18        0.689334     0.708302  0.698689      0.774788   \n",
       "Gradient_Boosted_12        0.689662     0.706403  0.697932      0.772152   \n",
       "Gradient_Boosted_8         0.689548     0.703949  0.696674      0.768681   \n",
       "Gradient_Boosted_7         0.688434     0.706111  0.697161      0.771293   \n",
       "\n",
       "                    Vectorization  n_estimators  max_depth  learning_rate  \\\n",
       "model_ID                                                                    \n",
       "Gradient_Boosted_19         Tfidf         100.0        NaN           1.00   \n",
       "Gradient_Boosted_18         Tfidf         100.0        NaN           1.00   \n",
       "Gradient_Boosted_12         Tfidf         200.0        NaN           1.00   \n",
       "Gradient_Boosted_8          Tfidf         100.0        NaN           1.10   \n",
       "Gradient_Boosted_7          Tfidf         100.0        NaN           1.01   \n",
       "\n",
       "                     ngrams_val  \n",
       "model_ID                         \n",
       "Gradient_Boosted_19         3.0  \n",
       "Gradient_Boosted_18         2.0  \n",
       "Gradient_Boosted_12         1.0  \n",
       "Gradient_Boosted_8          1.0  \n",
       "Gradient_Boosted_7          1.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e49d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_info_df.to_csv('Current_model_information_20Feb2023_V5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6516d0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "0   Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "1   Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "2   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "3    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "4    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "5    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "6             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "7   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "8            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "9             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "10            LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "11            LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "12            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "13  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "14  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "15   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "16            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "17           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "18   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "19            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "20            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "21            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "22      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "23  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "24  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "25  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "26   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "27   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "28      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "29      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "30   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "31        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "32            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "33      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "34        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "35     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "36        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "37     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "38        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "39     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "40     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "41   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "42   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "43  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "44                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "45                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "46                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "47                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "48                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "49                  NaN    NaN    NaN    NaN        NaN              NaN   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "0       0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "1       0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "2       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "3       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "4       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "5       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "6       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "7       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "8       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "9       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "10      0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "11      0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "12      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "13      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "14      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "15      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "16      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "17      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "18      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "19      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "20      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "21      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "22      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "23      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "24      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "25      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "26      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "27      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "28      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "29      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "30      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "31      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "32      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "33      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "34      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "35      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "36      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "37      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "38      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "39      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "40      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "41      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "42      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "43      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "44           NaN       NaN            NaN       NaN             NaN   \n",
       "45           NaN       NaN            NaN       NaN             NaN   \n",
       "46           NaN       NaN            NaN       NaN             NaN   \n",
       "47           NaN       NaN            NaN       NaN             NaN   \n",
       "48           NaN       NaN            NaN       NaN             NaN   \n",
       "49           NaN       NaN            NaN       NaN             NaN   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "0      0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "1      0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "2      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "3      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "4      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "5      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "6      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "7      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "8      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "9      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "10     0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "11     0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "12     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "13     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "14     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "15     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "16     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "17     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "18     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "19     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "20     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "21     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "22     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "23     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "24     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "25     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "26     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "27     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "28     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "29     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "30     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "31     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "32     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "33     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "34     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "35     0.851142  0.689021      0.714669         Count           NaN   \n",
       "36     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "37     0.584857  0.595352      0.637564         Count           NaN   \n",
       "38     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "39     0.537010  0.548024      0.563574         Count           NaN   \n",
       "40     0.524011  0.534830      0.526223         Count           NaN   \n",
       "41     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "42     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "43     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "44          NaN       NaN           NaN           NaN           NaN   \n",
       "45          NaN       NaN           NaN           NaN           NaN   \n",
       "46          NaN       NaN           NaN           NaN           NaN   \n",
       "47          NaN       NaN           NaN           NaN           NaN   \n",
       "48          NaN       NaN           NaN           NaN           NaN   \n",
       "49          NaN       NaN           NaN           NaN           NaN   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "0         NaN           1.00         3.0  \n",
       "1         NaN           1.00         2.0  \n",
       "2         NaN           1.00         1.0  \n",
       "3         NaN           1.10         1.0  \n",
       "4         NaN           1.01         1.0  \n",
       "5         NaN           1.00         1.0  \n",
       "6         NaN            NaN         1.0  \n",
       "7         NaN           0.10         1.0  \n",
       "8         NaN            NaN         1.0  \n",
       "9         NaN            NaN         1.0  \n",
       "10        NaN            NaN         1.0  \n",
       "11        NaN            NaN         1.0  \n",
       "12        NaN            NaN         1.0  \n",
       "13        NaN           0.10         3.0  \n",
       "14        NaN           0.10         2.0  \n",
       "15        NaN           0.10         1.0  \n",
       "16        NaN            NaN         1.0  \n",
       "17        NaN            NaN         1.0  \n",
       "18        NaN           1.00         1.0  \n",
       "19        NaN            NaN         1.0  \n",
       "20        NaN            NaN         1.0  \n",
       "21        NaN            NaN         1.0  \n",
       "22      100.0            NaN         1.0  \n",
       "23        NaN           0.01         1.0  \n",
       "24        NaN           0.01         3.0  \n",
       "25        NaN           0.01         2.0  \n",
       "26        NaN           0.01         1.0  \n",
       "27        NaN           0.10         1.0  \n",
       "28       10.0            NaN         1.0  \n",
       "29      100.0            NaN         1.0  \n",
       "30        NaN           0.01         1.0  \n",
       "31        NaN            NaN         1.0  \n",
       "32        NaN            NaN         1.0  \n",
       "33       10.0            NaN         1.0  \n",
       "34        NaN            NaN         1.0  \n",
       "35        NaN            NaN         1.0  \n",
       "36        NaN            NaN         1.0  \n",
       "37        NaN            NaN         1.0  \n",
       "38        NaN            NaN         1.0  \n",
       "39        NaN            NaN         1.0  \n",
       "40        NaN            NaN         1.0  \n",
       "41        NaN          10.00         1.0  \n",
       "42        NaN          10.00         1.0  \n",
       "43        NaN          10.00         1.0  \n",
       "44        NaN            NaN         2.0  \n",
       "45        NaN            NaN         3.0  \n",
       "46        NaN            NaN         2.0  \n",
       "47        NaN            NaN         3.0  \n",
       "48        NaN            NaN         2.0  \n",
       "49        NaN            NaN         3.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = ML_info_df.reset_index()\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bcf911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "0   Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "1   Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "2   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "3    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "4    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "5    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "6             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "7   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "8            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "9             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "10            LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "11            LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "12            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "13  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "14  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "15   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "16            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "17           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "18   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "19            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "20            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "21            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "22      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "23  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "24  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "25  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "26   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "27   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "28      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "29      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "30   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "31        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "32            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "33      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "34        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "35     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "36        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "37     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "38        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "39     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "40     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "41   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "42   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "43  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "0       0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "1       0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "2       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "3       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "4       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "5       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "6       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "7       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "8       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "9       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "10      0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "11      0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "12      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "13      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "14      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "15      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "16      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "17      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "18      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "19      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "20      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "21      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "22      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "23      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "24      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "25      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "26      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "27      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "28      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "29      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "30      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "31      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "32      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "33      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "34      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "35      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "36      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "37      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "38      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "39      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "40      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "41      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "42      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "43      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "0      0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "1      0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "2      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "3      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "4      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "5      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "6      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "7      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "8      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "9      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "10     0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "11     0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "12     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "13     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "14     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "15     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "16     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "17     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "18     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "19     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "20     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "21     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "22     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "23     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "24     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "25     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "26     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "27     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "28     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "29     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "30     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "31     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "32     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "33     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "34     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "35     0.851142  0.689021      0.714669         Count           NaN   \n",
       "36     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "37     0.584857  0.595352      0.637564         Count           NaN   \n",
       "38     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "39     0.537010  0.548024      0.563574         Count           NaN   \n",
       "40     0.524011  0.534830      0.526223         Count           NaN   \n",
       "41     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "42     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "43     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "0         NaN           1.00         3.0  \n",
       "1         NaN           1.00         2.0  \n",
       "2         NaN           1.00         1.0  \n",
       "3         NaN           1.10         1.0  \n",
       "4         NaN           1.01         1.0  \n",
       "5         NaN           1.00         1.0  \n",
       "6         NaN            NaN         1.0  \n",
       "7         NaN           0.10         1.0  \n",
       "8         NaN            NaN         1.0  \n",
       "9         NaN            NaN         1.0  \n",
       "10        NaN            NaN         1.0  \n",
       "11        NaN            NaN         1.0  \n",
       "12        NaN            NaN         1.0  \n",
       "13        NaN           0.10         3.0  \n",
       "14        NaN           0.10         2.0  \n",
       "15        NaN           0.10         1.0  \n",
       "16        NaN            NaN         1.0  \n",
       "17        NaN            NaN         1.0  \n",
       "18        NaN           1.00         1.0  \n",
       "19        NaN            NaN         1.0  \n",
       "20        NaN            NaN         1.0  \n",
       "21        NaN            NaN         1.0  \n",
       "22      100.0            NaN         1.0  \n",
       "23        NaN           0.01         1.0  \n",
       "24        NaN           0.01         3.0  \n",
       "25        NaN           0.01         2.0  \n",
       "26        NaN           0.01         1.0  \n",
       "27        NaN           0.10         1.0  \n",
       "28       10.0            NaN         1.0  \n",
       "29      100.0            NaN         1.0  \n",
       "30        NaN           0.01         1.0  \n",
       "31        NaN            NaN         1.0  \n",
       "32        NaN            NaN         1.0  \n",
       "33       10.0            NaN         1.0  \n",
       "34        NaN            NaN         1.0  \n",
       "35        NaN            NaN         1.0  \n",
       "36        NaN            NaN         1.0  \n",
       "37        NaN            NaN         1.0  \n",
       "38        NaN            NaN         1.0  \n",
       "39        NaN            NaN         1.0  \n",
       "40        NaN            NaN         1.0  \n",
       "41        NaN          10.00         1.0  \n",
       "42        NaN          10.00         1.0  \n",
       "43        NaN          10.00         1.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df = ML_info_df.iloc[:-6]\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a37313be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [34:27<00:00, 2067.28s/it]\u001b[A\n",
      "100%|██████████| 1/1 [34:27<00:00, 2067.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gradient_Boosted_20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728615</td>\n",
       "      <td>0.721749</td>\n",
       "      <td>0.742919</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>0.811902</td>\n",
       "      <td>0.701711</td>\n",
       "      <td>0.696157</td>\n",
       "      <td>0.704271</td>\n",
       "      <td>0.700190</td>\n",
       "      <td>0.777393</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "0   Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "1   Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "2   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "3    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "4    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "5    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "6             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "7   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "8            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "9             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "10            LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "11            LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "12            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "13  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "14  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "15   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "16            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "17           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "18   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "19            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "20            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "21            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "22      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "23  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "24  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "25  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "26   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "27   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "28      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "29      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "30   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "31        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "32            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "33      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "34        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "35     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "36        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "37     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "38        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "39     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "40     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "41   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "42   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "43  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "44  Gradient_Boosted_20    NaN    NaN    NaN   0.728615         0.721749   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "0       0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "1       0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "2       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "3       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "4       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "5       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "6       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "7       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "8       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "9       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "10      0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "11      0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "12      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "13      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "14      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "15      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "16      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "17      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "18      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "19      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "20      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "21      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "22      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "23      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "24      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "25      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "26      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "27      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "28      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "29      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "30      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "31      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "32      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "33      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "34      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "35      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "36      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "37      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "38      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "39      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "40      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "41      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "42      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "43      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "44      0.742919  0.732181       0.811902  0.701711        0.696157   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "0      0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "1      0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "2      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "3      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "4      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "5      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "6      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "7      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "8      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "9      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "10     0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "11     0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "12     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "13     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "14     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "15     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "16     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "17     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "18     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "19     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "20     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "21     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "22     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "23     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "24     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "25     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "26     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "27     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "28     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "29     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "30     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "31     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "32     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "33     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "34     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "35     0.851142  0.689021      0.714669         Count           NaN   \n",
       "36     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "37     0.584857  0.595352      0.637564         Count           NaN   \n",
       "38     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "39     0.537010  0.548024      0.563574         Count           NaN   \n",
       "40     0.524011  0.534830      0.526223         Count           NaN   \n",
       "41     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "42     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "43     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "44     0.704271  0.700190      0.777393         Tfidf         200.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "0         NaN           1.00         3.0  \n",
       "1         NaN           1.00         2.0  \n",
       "2         NaN           1.00         1.0  \n",
       "3         NaN           1.10         1.0  \n",
       "4         NaN           1.01         1.0  \n",
       "5         NaN           1.00         1.0  \n",
       "6         NaN            NaN         1.0  \n",
       "7         NaN           0.10         1.0  \n",
       "8         NaN            NaN         1.0  \n",
       "9         NaN            NaN         1.0  \n",
       "10        NaN            NaN         1.0  \n",
       "11        NaN            NaN         1.0  \n",
       "12        NaN            NaN         1.0  \n",
       "13        NaN           0.10         3.0  \n",
       "14        NaN           0.10         2.0  \n",
       "15        NaN           0.10         1.0  \n",
       "16        NaN            NaN         1.0  \n",
       "17        NaN            NaN         1.0  \n",
       "18        NaN           1.00         1.0  \n",
       "19        NaN            NaN         1.0  \n",
       "20        NaN            NaN         1.0  \n",
       "21        NaN            NaN         1.0  \n",
       "22      100.0            NaN         1.0  \n",
       "23        NaN           0.01         1.0  \n",
       "24        NaN           0.01         3.0  \n",
       "25        NaN           0.01         2.0  \n",
       "26        NaN           0.01         1.0  \n",
       "27        NaN           0.10         1.0  \n",
       "28       10.0            NaN         1.0  \n",
       "29      100.0            NaN         1.0  \n",
       "30        NaN           0.01         1.0  \n",
       "31        NaN            NaN         1.0  \n",
       "32        NaN            NaN         1.0  \n",
       "33       10.0            NaN         1.0  \n",
       "34        NaN            NaN         1.0  \n",
       "35        NaN            NaN         1.0  \n",
       "36        NaN            NaN         1.0  \n",
       "37        NaN            NaN         1.0  \n",
       "38        NaN            NaN         1.0  \n",
       "39        NaN            NaN         1.0  \n",
       "40        NaN            NaN         1.0  \n",
       "41        NaN          10.00         1.0  \n",
       "42        NaN          10.00         1.0  \n",
       "43        NaN          10.00         1.0  \n",
       "44        NaN           1.00         2.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_ML_list = []\n",
    "index_val = 20\n",
    "tfidf_ngram_test_tuples = [(X_train_tfidf_2, y_train_tfidf_2, X_test_tfidf_2, y_test_tfidf_2),\n",
    "                           (X_train_tfidf_3, y_train_tfidf_3, X_test_tfidf_3, y_test_tfidf_3)]\n",
    "\n",
    "for n_estimators_val in tqdm([200]):\n",
    "    for learning_rate_val in tqdm([1]):\n",
    "        for ngrams_tuple_val in np.arange(1):\n",
    "            ngrams_tuple = tfidf_ngram_test_tuples[ngrams_tuple_val]\n",
    "            X_train_temp = ngrams_tuple[0]\n",
    "            y_train_temp = ngrams_tuple[1]\n",
    "            X_test_temp = ngrams_tuple[2]\n",
    "            y_test_temp = ngrams_tuple[3]\n",
    "            model_name = \"Gradient_Boosted_{}\".format(str(index_val))\n",
    "            clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, random_state=0)\n",
    "            clf.fit(X_train_temp, y_train_temp)\n",
    "            y_train_pred = clf.predict(X_train_temp)\n",
    "            y_test_pred = clf.predict(X_test_temp)\n",
    "            results_dict = obtain_train_and_test_metrics(y_train_temp, y_train_pred, y_test_temp, y_test_pred)\n",
    "            results_dict['train_roc_auc'] = obtain_roc_auc_score(clf, X_train_temp, y_train_temp)\n",
    "            results_dict['test_roc_auc'] = obtain_roc_auc_score(clf, X_test_temp, y_test_temp)\n",
    "            results_dict['model_ID'] = model_name\n",
    "            results_dict['n_estimators'] = n_estimators_val\n",
    "            results_dict['learning_rate'] = learning_rate_val\n",
    "            results_dict['Vectorization'] = 'Tfidf'\n",
    "            results_dict['ngrams_val'] = (ngrams_tuple_val + 2)\n",
    "            temp_ML_list.append(results_dict)\n",
    "            index_val += 1\n",
    "        \n",
    "temp_ML_info_df = pd.DataFrame(data=temp_ML_list, columns=all_columns)\n",
    "\n",
    "ML_info_df = pd.concat([ML_info_df, temp_ML_info_df], ignore_index=True)\n",
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6276a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_info_df = ML_info_df.sort_values(['test_acc'], ascending=False)\n",
    "ML_info_df.to_csv('Current_model_information_20Feb2023_V6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f1fdfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>ngrams_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gradient_Boosted_20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728615</td>\n",
       "      <td>0.721749</td>\n",
       "      <td>0.742919</td>\n",
       "      <td>0.732181</td>\n",
       "      <td>0.811902</td>\n",
       "      <td>0.701711</td>\n",
       "      <td>0.696157</td>\n",
       "      <td>0.704271</td>\n",
       "      <td>0.700190</td>\n",
       "      <td>0.777393</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosted_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.721721</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.698908</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.774761</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient_Boosted_18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.705792</td>\n",
       "      <td>0.733834</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.794199</td>\n",
       "      <td>0.697853</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>0.708302</td>\n",
       "      <td>0.698689</td>\n",
       "      <td>0.774788</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient_Boosted_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722984</td>\n",
       "      <td>0.717358</td>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.725930</td>\n",
       "      <td>0.803206</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.689662</td>\n",
       "      <td>0.706403</td>\n",
       "      <td>0.697932</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosted_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709703</td>\n",
       "      <td>0.704716</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.712547</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.703949</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0.768681</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_Boosted_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>0.704347</td>\n",
       "      <td>0.722601</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosted_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709140</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.713336</td>\n",
       "      <td>0.786520</td>\n",
       "      <td>0.696582</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>0.698178</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg_V8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.717606</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.716518</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.687321</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.681837</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.755119</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient_Boosted_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>0.698121</td>\n",
       "      <td>0.763517</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.674024</td>\n",
       "      <td>0.710054</td>\n",
       "      <td>0.691570</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogReg_V11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.723086</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>0.686209</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.753444</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg_V3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.703303</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.685920</td>\n",
       "      <td>0.681430</td>\n",
       "      <td>0.685371</td>\n",
       "      <td>0.683395</td>\n",
       "      <td>0.751441</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg_V5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.697756</td>\n",
       "      <td>0.700380</td>\n",
       "      <td>0.699066</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.682731</td>\n",
       "      <td>0.750606</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogReg_V4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>0.685559</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.683765</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogReg_V7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.726689</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.725554</td>\n",
       "      <td>0.800077</td>\n",
       "      <td>0.684981</td>\n",
       "      <td>0.682570</td>\n",
       "      <td>0.678682</td>\n",
       "      <td>0.680620</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient_Boosted_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685952</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.711520</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.756937</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>0.671210</td>\n",
       "      <td>0.706228</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.755358</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient_Boosted_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686144</td>\n",
       "      <td>0.678075</td>\n",
       "      <td>0.707209</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.756463</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>0.672466</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.687052</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient_Boosted_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.672092</td>\n",
       "      <td>0.708742</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>0.751177</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogReg_V6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.816374</td>\n",
       "      <td>0.678422</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogReg_V10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.744416</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.741139</td>\n",
       "      <td>0.743322</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.675706</td>\n",
       "      <td>0.673660</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.670725</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gradient_Boosted_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.663087</td>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>0.740512</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.659993</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.680359</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogReg_V2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.665187</td>\n",
       "      <td>0.669791</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.657741</td>\n",
       "      <td>0.662236</td>\n",
       "      <td>0.659981</td>\n",
       "      <td>0.722632</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogReg_V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.666398</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.667375</td>\n",
       "      <td>0.726283</td>\n",
       "      <td>0.662458</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660101</td>\n",
       "      <td>0.722717</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_V1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.667430</td>\n",
       "      <td>0.726320</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>0.662704</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random_Forest_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.892141</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.894568</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gradient_Boosted_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.699021</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.724507</td>\n",
       "      <td>0.661735</td>\n",
       "      <td>0.647003</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.724536</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient_Boosted_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.651219</td>\n",
       "      <td>0.693010</td>\n",
       "      <td>0.671465</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666912</td>\n",
       "      <td>0.717345</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient_Boosted_14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660265</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.672844</td>\n",
       "      <td>0.716818</td>\n",
       "      <td>0.659034</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient_Boosted_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655790</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.705089</td>\n",
       "      <td>0.671669</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.700444</td>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.714708</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gradient_Boosted_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.701791</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.713152</td>\n",
       "      <td>0.653298</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.713143</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random_Forest_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.721950</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.718871</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.631647</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random_Forest_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852101</td>\n",
       "      <td>0.842257</td>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.634934</td>\n",
       "      <td>0.670970</td>\n",
       "      <td>0.652455</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gradient_Boosted_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640726</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>0.640773</td>\n",
       "      <td>0.644312</td>\n",
       "      <td>0.610942</td>\n",
       "      <td>0.627183</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BernoulliNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.603514</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.711188</td>\n",
       "      <td>0.635355</td>\n",
       "      <td>0.641825</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>0.617239</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogReg_V9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.796704</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.874830</td>\n",
       "      <td>0.632552</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.688739</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random_Forest_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632834</td>\n",
       "      <td>0.617492</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.654203</td>\n",
       "      <td>0.683249</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.611932</td>\n",
       "      <td>0.692995</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BernoulliNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653880</td>\n",
       "      <td>0.660473</td>\n",
       "      <td>0.631441</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.729765</td>\n",
       "      <td>0.626976</td>\n",
       "      <td>0.627493</td>\n",
       "      <td>0.604837</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MultinominalNB_3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662967</td>\n",
       "      <td>0.614246</td>\n",
       "      <td>0.873781</td>\n",
       "      <td>0.721380</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>0.578778</td>\n",
       "      <td>0.851142</td>\n",
       "      <td>0.689021</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BernoulliNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670610</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.653611</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.609047</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.598805</td>\n",
       "      <td>0.651346</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultinominalNB_2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726751</td>\n",
       "      <td>0.740882</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.717900</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.606793</td>\n",
       "      <td>0.606231</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.595352</td>\n",
       "      <td>0.637564</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BernoulliNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.689154</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.679115</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.579928</td>\n",
       "      <td>0.619243</td>\n",
       "      <td>Binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MultinominalNB_1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742246</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>0.819968</td>\n",
       "      <td>0.561906</td>\n",
       "      <td>0.559498</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.548024</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MultinominalNB_0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745344</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.549178</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.526223</td>\n",
       "      <td>Count</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gradient_Boosted_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gradient_Boosted_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient_Boosted_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.279989</td>\n",
       "      <td>0.334749</td>\n",
       "      <td>0.444095</td>\n",
       "      <td>0.447080</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.336822</td>\n",
       "      <td>0.445331</td>\n",
       "      <td>Tfidf</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_ID  alpha      C solver  train_acc  train_precision  \\\n",
       "44  Gradient_Boosted_20    NaN    NaN    NaN   0.728615         0.721749   \n",
       "0   Gradient_Boosted_19    NaN    NaN    NaN   0.716714         0.708277   \n",
       "1   Gradient_Boosted_18    NaN    NaN    NaN   0.714348         0.705792   \n",
       "2   Gradient_Boosted_12    NaN    NaN    NaN   0.722984         0.717358   \n",
       "3    Gradient_Boosted_8    NaN    NaN    NaN   0.709703         0.704716   \n",
       "4    Gradient_Boosted_7    NaN    NaN    NaN   0.710028         0.704347   \n",
       "5    Gradient_Boosted_6    NaN    NaN    NaN   0.709140         0.702284   \n",
       "6             LogReg_V8    NaN   1.00   saga   0.717606         0.717540   \n",
       "7   Gradient_Boosted_11    NaN    NaN    NaN   0.690778         0.681064   \n",
       "8            LogReg_V11    NaN  10.00   saga   0.723847         0.724117   \n",
       "9             LogReg_V3    NaN   0.10  lbfgs   0.701317         0.699966   \n",
       "10            LogReg_V5    NaN   0.10   saga   0.698901         0.697756   \n",
       "11            LogReg_V4    NaN   0.10    sag   0.700111         0.698899   \n",
       "12            LogReg_V7    NaN   1.00    sag   0.726346         0.726689   \n",
       "13  Gradient_Boosted_17    NaN    NaN    NaN   0.685952         0.676368   \n",
       "14  Gradient_Boosted_16    NaN    NaN    NaN   0.686144         0.678075   \n",
       "15   Gradient_Boosted_5    NaN    NaN    NaN   0.681900         0.672092   \n",
       "16            LogReg_V6    NaN   1.00  lbfgs   0.740674         0.741076   \n",
       "17           LogReg_V10    NaN  10.00    sag   0.744416         0.745518   \n",
       "18   Gradient_Boosted_2    NaN    NaN    NaN   0.674084         0.663087   \n",
       "19            LogReg_V2    NaN   0.01   saga   0.666774         0.665187   \n",
       "20            LogReg_V0    NaN   0.01  lbfgs   0.666398         0.664549   \n",
       "21            LogReg_V1    NaN   0.01    sag   0.666608         0.664908   \n",
       "22      Random_Forest_3    NaN    NaN    NaN   0.894421         0.892141   \n",
       "23  Gradient_Boosted_10    NaN    NaN    NaN   0.662599         0.651013   \n",
       "24  Gradient_Boosted_15    NaN    NaN    NaN   0.661374         0.651219   \n",
       "25  Gradient_Boosted_14    NaN    NaN    NaN   0.660265         0.648022   \n",
       "26   Gradient_Boosted_4    NaN    NaN    NaN   0.655790         0.641274   \n",
       "27   Gradient_Boosted_1    NaN    NaN    NaN   0.654949         0.641138   \n",
       "28      Random_Forest_2    NaN    NaN    NaN   0.659630         0.641422   \n",
       "29      Random_Forest_1    NaN    NaN    NaN   0.852101         0.842257   \n",
       "30   Gradient_Boosted_0    NaN    NaN    NaN   0.640726         0.648237   \n",
       "31        BernoulliNB_3  10.00    NaN    NaN   0.642958         0.654526   \n",
       "32            LogReg_V9    NaN  10.00  lbfgs   0.796704         0.796577   \n",
       "33      Random_Forest_0    NaN    NaN    NaN   0.632834         0.617492   \n",
       "34        BernoulliNB_2   1.00    NaN    NaN   0.653880         0.660473   \n",
       "35     MultinominalNB_3  10.00    NaN    NaN   0.662967         0.614246   \n",
       "36        BernoulliNB_1   0.10    NaN    NaN   0.670610         0.676000   \n",
       "37     MultinominalNB_2   1.00    NaN    NaN   0.726751         0.740882   \n",
       "38        BernoulliNB_0   0.01    NaN    NaN   0.684143         0.689154   \n",
       "39     MultinominalNB_1   0.10    NaN    NaN   0.742246         0.763469   \n",
       "40     MultinominalNB_0   0.01    NaN    NaN   0.745344         0.767017   \n",
       "41   Gradient_Boosted_9    NaN    NaN    NaN   0.444314         0.416136   \n",
       "42   Gradient_Boosted_3    NaN    NaN    NaN   0.444314         0.416136   \n",
       "43  Gradient_Boosted_13    NaN    NaN    NaN   0.444314         0.416136   \n",
       "\n",
       "    train_recall  train_f1  train_roc_auc  test_acc  test_precision  \\\n",
       "44      0.742919  0.732181       0.811902  0.701711        0.696157   \n",
       "0       0.735686  0.721721       0.796982  0.698908        0.692257   \n",
       "1       0.733834  0.719540       0.794199  0.697853        0.689334   \n",
       "2       0.734709  0.725930       0.803206  0.697579        0.689662   \n",
       "3       0.720554  0.712547       0.786444  0.696827        0.689548   \n",
       "4       0.722601  0.713357       0.787408  0.696596        0.688434   \n",
       "5       0.724742  0.713336       0.786520  0.696582        0.687157   \n",
       "6       0.716518  0.717029       0.789683  0.687321        0.684657   \n",
       "7       0.716055  0.698121       0.763517  0.686758        0.674024   \n",
       "8       0.722058  0.723086       0.797091  0.686209        0.684105   \n",
       "9       0.703303  0.701630       0.769428  0.685920        0.681430   \n",
       "10      0.700380  0.699066       0.766192  0.685573        0.681440   \n",
       "11      0.701755  0.700324       0.767600  0.685559        0.681515   \n",
       "12      0.724424  0.725554       0.800077  0.684981        0.682570   \n",
       "13      0.711520  0.693499       0.756937  0.683608        0.671210   \n",
       "14      0.707209  0.692335       0.756463  0.683579        0.672466   \n",
       "15      0.708742  0.689931       0.751177  0.679029        0.666215   \n",
       "16      0.738781  0.739927       0.816374  0.678422        0.675963   \n",
       "17      0.741139  0.743322       0.820612  0.675706        0.673660   \n",
       "18      0.706037  0.683888       0.740512  0.673755        0.659993   \n",
       "19      0.669791  0.667481       0.726328  0.662516        0.657741   \n",
       "20      0.670225  0.667375       0.726283  0.662458        0.657518   \n",
       "21      0.669972  0.667430       0.726320  0.662386        0.657423   \n",
       "22      0.897007  0.894568       0.963894  0.662082        0.649276   \n",
       "23      0.699021  0.674163       0.724507  0.661735        0.647003   \n",
       "24      0.693010  0.671465       0.717713  0.659973        0.646846   \n",
       "25      0.699643  0.672844       0.716818  0.659034        0.643794   \n",
       "26      0.705089  0.671669       0.714714  0.653905        0.636385   \n",
       "27      0.701791  0.670095       0.713152  0.653298        0.636538   \n",
       "28      0.721950  0.679308       0.718871  0.652128        0.631647   \n",
       "29      0.865998  0.853963       0.931401  0.646465        0.634934   \n",
       "30      0.613300  0.630285       0.695334  0.640773        0.644312   \n",
       "31      0.603514  0.627986       0.711188  0.635355        0.641825   \n",
       "32      0.796191  0.796384       0.874830  0.632552        0.629809   \n",
       "33      0.695556  0.654203       0.683249  0.630804        0.611932   \n",
       "34      0.631441  0.645631       0.729765  0.626976        0.627493   \n",
       "35      0.873781  0.721380       0.764139  0.620012        0.578778   \n",
       "36      0.653611  0.664617       0.751843  0.609047        0.607972   \n",
       "37      0.696301  0.717900       0.796255  0.606793        0.606231   \n",
       "38      0.669365  0.679115       0.768589  0.589341        0.586875   \n",
       "39      0.700974  0.730888       0.819968  0.561906        0.559498   \n",
       "40      0.703787  0.734043       0.826907  0.549178        0.546105   \n",
       "41      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "42      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "43      0.279989  0.334749       0.444095  0.447080        0.413997   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc Vectorization  n_estimators  \\\n",
       "44     0.704271  0.700190      0.777393         Tfidf         200.0   \n",
       "0      0.704329  0.698241      0.774761         Tfidf         100.0   \n",
       "1      0.708302  0.698689      0.774788         Tfidf         100.0   \n",
       "2      0.706403  0.697932      0.772152         Tfidf         200.0   \n",
       "3      0.703949  0.696674      0.768681         Tfidf         100.0   \n",
       "4      0.706111  0.697161      0.771293         Tfidf         100.0   \n",
       "5      0.709558  0.698178      0.769949         Tfidf         100.0   \n",
       "6      0.681837  0.683244      0.755119         Tfidf           NaN   \n",
       "7      0.710054  0.691570      0.759933         Tfidf         200.0   \n",
       "8      0.679149  0.681618      0.753444         Tfidf           NaN   \n",
       "9      0.685371  0.683395      0.751441         Tfidf           NaN   \n",
       "10     0.684028  0.682731      0.750606         Tfidf           NaN   \n",
       "11     0.683765  0.682638      0.751067         Tfidf           NaN   \n",
       "12     0.678682  0.680620      0.752376         Tfidf           NaN   \n",
       "13     0.706228  0.688274      0.755358         Tfidf         100.0   \n",
       "14     0.702284  0.687052      0.754663         Tfidf         100.0   \n",
       "15     0.703482  0.684341      0.749778         Tfidf         100.0   \n",
       "16     0.671876  0.673913      0.744277         Tfidf           NaN   \n",
       "17     0.667816  0.670725      0.740492         Tfidf           NaN   \n",
       "18     0.702021  0.680359      0.740950         Tfidf          10.0   \n",
       "19     0.662236  0.659981      0.722632         Tfidf           NaN   \n",
       "20     0.662704  0.660101      0.722717         Tfidf           NaN   \n",
       "21     0.662704  0.660053      0.722694         Tfidf           NaN   \n",
       "22     0.688877  0.668490      0.729804           NaN         100.0   \n",
       "23     0.695537  0.670392      0.724536         Tfidf         200.0   \n",
       "24     0.688263  0.666912      0.717345         Tfidf         100.0   \n",
       "25     0.695303  0.668558      0.716524         Tfidf         100.0   \n",
       "26     0.700444  0.666880      0.714708         Tfidf         100.0   \n",
       "27     0.696968  0.665384      0.713143         Tfidf          10.0   \n",
       "28     0.711632  0.669258      0.711267           NaN         100.0   \n",
       "29     0.670970  0.652455      0.708200           NaN          10.0   \n",
       "30     0.610942  0.627183      0.694319         Tfidf          10.0   \n",
       "31     0.594467  0.617239      0.696557        Binary           NaN   \n",
       "32     0.623591  0.626684      0.688739         Tfidf           NaN   \n",
       "33     0.692995  0.649946      0.678526           NaN          10.0   \n",
       "34     0.604837  0.615957      0.681550        Binary           NaN   \n",
       "35     0.851142  0.689021      0.714669         Count           NaN   \n",
       "36     0.589911  0.598805      0.651346        Binary           NaN   \n",
       "37     0.584857  0.595352      0.637564         Count           NaN   \n",
       "38     0.573144  0.579928      0.619243        Binary           NaN   \n",
       "39     0.537010  0.548024      0.563574         Count           NaN   \n",
       "40     0.524011  0.534830      0.526223         Count           NaN   \n",
       "41     0.283899  0.336822      0.445331         Tfidf         100.0   \n",
       "42     0.283899  0.336822      0.445331         Tfidf          10.0   \n",
       "43     0.283899  0.336822      0.445331         Tfidf         200.0   \n",
       "\n",
       "    max_depth  learning_rate  ngrams_val  \n",
       "44        NaN           1.00         2.0  \n",
       "0         NaN           1.00         3.0  \n",
       "1         NaN           1.00         2.0  \n",
       "2         NaN           1.00         1.0  \n",
       "3         NaN           1.10         1.0  \n",
       "4         NaN           1.01         1.0  \n",
       "5         NaN           1.00         1.0  \n",
       "6         NaN            NaN         1.0  \n",
       "7         NaN           0.10         1.0  \n",
       "8         NaN            NaN         1.0  \n",
       "9         NaN            NaN         1.0  \n",
       "10        NaN            NaN         1.0  \n",
       "11        NaN            NaN         1.0  \n",
       "12        NaN            NaN         1.0  \n",
       "13        NaN           0.10         3.0  \n",
       "14        NaN           0.10         2.0  \n",
       "15        NaN           0.10         1.0  \n",
       "16        NaN            NaN         1.0  \n",
       "17        NaN            NaN         1.0  \n",
       "18        NaN           1.00         1.0  \n",
       "19        NaN            NaN         1.0  \n",
       "20        NaN            NaN         1.0  \n",
       "21        NaN            NaN         1.0  \n",
       "22      100.0            NaN         1.0  \n",
       "23        NaN           0.01         1.0  \n",
       "24        NaN           0.01         3.0  \n",
       "25        NaN           0.01         2.0  \n",
       "26        NaN           0.01         1.0  \n",
       "27        NaN           0.10         1.0  \n",
       "28       10.0            NaN         1.0  \n",
       "29      100.0            NaN         1.0  \n",
       "30        NaN           0.01         1.0  \n",
       "31        NaN            NaN         1.0  \n",
       "32        NaN            NaN         1.0  \n",
       "33       10.0            NaN         1.0  \n",
       "34        NaN            NaN         1.0  \n",
       "35        NaN            NaN         1.0  \n",
       "36        NaN            NaN         1.0  \n",
       "37        NaN            NaN         1.0  \n",
       "38        NaN            NaN         1.0  \n",
       "39        NaN            NaN         1.0  \n",
       "40        NaN            NaN         1.0  \n",
       "41        NaN          10.00         1.0  \n",
       "42        NaN          10.00         1.0  \n",
       "43        NaN          10.00         1.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9147cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
